{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Sensor Bias\n",
    "\n",
    "We want to compute the joint posterior over sensors' biases in a 2-D tracking setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import funsor\n",
    "import funsor.pyro\n",
    "import funsor.distributions as f_dist\n",
    "import funsor.ops as ops\n",
    "from funsor.pyro.convert import dist_to_funsor, mvn_to_funsor, matrix_and_mvn_to_funsor, tensor_to_funsor\n",
    "from funsor.interpreter import interpretation, reinterpret\n",
    "from funsor.optimizer import apply_optimizer\n",
    "from funsor.terms import lazy, eager_or_die\n",
    "from funsor.domains import bint, reals\n",
    "from funsor.torch import Tensor, Variable\n",
    "from funsor.sum_product import sequential_sum_product\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate some synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sensors = 5\n",
    "num_frames = 100\n",
    "\n",
    "# simulate biased sensors\n",
    "sensors  = []\n",
    "for _ in range(num_sensors):\n",
    "    bias = 0.5 * torch.randn(2)\n",
    "    sensors.append(bias)\n",
    "\n",
    "# simulate a single track\n",
    "# TODO heterogeneous time\n",
    "partial_obs = []\n",
    "z = 10 * torch.rand(2)  # initial state\n",
    "v = 2 * torch.randn(2)  # velocity\n",
    "for t in range(num_frames):\n",
    "    # Advance latent state.\n",
    "    z += v + 0.1 * torch.randn(2)\n",
    "#     z.clamp_(min=0, max=10)  # keep in the box\n",
    "    \n",
    "    # Observe via a random sensor.\n",
    "    sensor_id = pyro.sample('id', dist.Categorical(torch.ones(num_sensors)))\n",
    "    x = z - sensors[sensor_id]\n",
    "    partial_obs.append({\"sensor_id\": sensor_id, \"x\": x})\n",
    "    \n",
    "# simulate all tracks\n",
    "full_observations = []\n",
    "z = 10 * torch.rand(5, 2)  # initial state\n",
    "v = 2 * torch.randn(5, 2)  # velocity\n",
    "for t in range(num_frames):\n",
    "    # Advance latent state.\n",
    "    z += v + 0.1 * torch.randn(5, 2)\n",
    "#     z.clamp_(min=0, max=10)  # keep in the box\n",
    "    \n",
    "    # Observe via a random sensor.\n",
    "    x = z - torch.stack(sensors)\n",
    "    full_observations.append(x)\n",
    "full_observations = torch.stack(full_observations)\n",
    "assert full_observations.shape == (num_frames, 5, 2)\n",
    "full_observations = Tensor(full_observations, OrderedDict([(\"time\", bint(num_frames))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up a tracking problem in Funsor. We start by modeling the biases of each sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': OrderedDict([('bias', reals(5, 2))]),\n",
       " 'output': reals(),\n",
       " 'fresh': frozenset(),\n",
       " 'bound': frozenset(),\n",
       " 'deltas': (),\n",
       " 'discrete': Tensor(-9.189385414123535, OrderedDict(), 'real'),\n",
       " 'gaussian': Gaussian(..., ((bias, reals(5, 2)),)),\n",
       " '_ast_values': ((),\n",
       "  Tensor(-9.189385414123535, OrderedDict(), 'real'),\n",
       "  Gaussian(..., ((bias, reals(5, 2)),)))}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO transform this to cholesky decomposition\n",
    "# print(bias_cov.shape)\n",
    "# bias_cov = bias_cov @ bias_cov.t()\n",
    "# create a joint Gaussian over biases\n",
    "\n",
    "# covs = [torch.eye(2, requires_grad=True) for i in range(num_sensors)]\n",
    "# bias_dist = 0.\n",
    "# for i in range(num_sensors):\n",
    "#     bias += funsor.pyro.convert.mvn_to_funsor(\n",
    "#         dist.MultivariateNormal(torch.zeros(2), covs[i]),\n",
    "# #         event_dims=(\"pos\",),\n",
    "# #         real_inputs=OrderedDict([(\"bias_{}\".format(i), reals(2))])\n",
    "#         real_inputs=OrderedDict([(\"bias\", reals(2))])\n",
    "#     )(value=\"bias_{}\".format(i))\n",
    "# bias_dist.__dict__\n",
    "\n",
    "# we can't write bias_dist as a sum of mvns because affine transformation\n",
    "# of mvns is not supported yet.  instead we will combine all the sensors\n",
    "# into a giant tensor\n",
    "bias_scales = torch.ones(2, requires_grad=True)  # This can be learned\n",
    "bias_dist = funsor.pyro.convert.mvn_to_funsor(\n",
    "    dist.MultivariateNormal(\n",
    "        torch.zeros(num_sensors * 2),\n",
    "        bias_scales.expand(num_sensors, 2).reshape(-1).diag_embed()\n",
    "    ),\n",
    "    real_inputs=OrderedDict([(\"bias\", reals(num_sensors, 2))])\n",
    ")\n",
    "bias_dist.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the filter in funsor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace as bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# this can be parameterized by a lower dimensional vector \n",
    "# to learn a structured transition matrix\n",
    "# eg a GP with a matern v=3/2 kernel\n",
    "# see paper for details \n",
    "\n",
    "# transition matrix from discretization as in \n",
    "# http://webee.technion.ac.il/people/shimkin/Estimation09/ch8_target.pdf\n",
    "T = 1.  # timestep\n",
    "trans_matrix_noise = torch.randn(1, requires_grad=True)\n",
    "trans_dist_cov = torch.tensor([[1./3 * T ** 3, 0.5 * T ** 2],\n",
    "                                  [0.5 * T ** 2, T]]) * trans_matrix_noise ** 2\n",
    "transition_matrix = torch.randn(2, 2, requires_grad=True)\n",
    "transition_matrix = torch.tensor([[1., T],\n",
    "                                  [0, 1]])\n",
    "\n",
    "class HMM(nn.Module):\n",
    "    def __init__(self, num_sensors):\n",
    "        init_dist = torch.distributions.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "        transition_dist = torch.distributions.MultivariateNormal(\n",
    "            torch.zeros(2), trans_dist_cov)\n",
    "        observation_matrix = torch.eye(2) + 0.2 * torch.randn(2, 2)\n",
    "        # this is the bias for all the sensors\n",
    "        biases = torch.zeros(num_sensors, 2, requires_grad=True)\n",
    "        observation_dist = torch.distributions.MultivariateNormal(\n",
    "            bias,\n",
    "            torch.eye(2))\n",
    "\n",
    "        self.init = dist_to_funsor(init_dist)(value=\"state\")\n",
    "        # inputs are the previous state ``state`` and the next state\n",
    "        self.trans = matrix_and_mvn_to_funsor(transition_matrix, transition_dist,\n",
    "                                         (\"time\",), \"state\", \"state(time=1)\")\n",
    "        self.obs = matrix_and_mvn_to_funsor(observation_matrix, observation_dist,\n",
    "                                       (\"time\",), \"state(time=1)\", \"value\")\n",
    "        super(HMM, self).__init__()\n",
    "    \n",
    "    def forward(track):\n",
    "        sensor_ids = torch.tensor([frame[\"sensor_id\"] for frame in track])\n",
    "        bias = self.biases[sensor_ids]\n",
    "        # we add bias to the observation as a global variable\n",
    "        # single interleaved track\n",
    "        sensor_ids = Tensor(\n",
    "            torch.tensor([frame[\"sensor_id\"] for frame in track]),\n",
    "            OrderedDict([(\"time\", bint(num_frames))]),\n",
    "            dtype=len(sensors)\n",
    "        )\n",
    "        \n",
    "#         biased_observations = Tensor(\n",
    "#             torch.stack([frame[\"x\"] for frame in track]),\n",
    "#             OrderedDict([(\"time\", bint(num_frames))])\n",
    "#         )\n",
    "\n",
    "        # incorporate sensor id in the observation by creating\n",
    "        # a free variable that has the signature\n",
    "        # inputs: bias of shape (num_sensors, 2), sensor_ids\n",
    "        # outputs shape 2\n",
    "        bias = Variable(\"bias\", reals(num_sensors, 2))#  [sensor_ids]\n",
    "        debiased_observations = track - bias\n",
    "    #     debiased_observations = biased_observations\n",
    "        # this indexing pattern is not implemented to sub into a Gaussian\n",
    "        # https://github.com/pyro-ppl/funsor/pull/220\n",
    "        # instead, we can use matrix_and_mvn_to_funsor and index  the proper latents and just \n",
    "        # observe naively\n",
    "\n",
    "    #     bias = Variable(\"bias\", reals(num_sensors, 2))\n",
    "    #     debiased_observations = all_tracks - bias\n",
    "        obs = obs(value=debiased_observations)\n",
    "    #     print(obs)\n",
    "\n",
    "        logp = trans + obs + bias_dist\n",
    "\n",
    "        bb()\n",
    "        \n",
    "        # collapse out the time variable\n",
    "        # TODO this can only handle homogeneous funsor types\n",
    "        logp = sequential_sum_product(ops.logaddexp, ops.add,\n",
    "                                      logp, \"time\", {\"state\": \"state(time=1)\"})\n",
    "        logp += init\n",
    "        # logaddexp across all states\n",
    "        logp = logp.reduce(ops.logaddexp, frozenset([\"state\", \"state(time=1)\"]))\n",
    "    #     # ensure we collapsed out the right dim\n",
    "    #     assert logp.data.dim() == 0\n",
    "        return logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Finally we have a result that is a joint Gaussian over the biases.\n",
    "We can\n",
    "1. optimize all parameters to maximize `result`\n",
    "2. estimate the joint distribution over all bias parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert to Funsor: [{'sensor_id': tensor(2), 'x': tensor([9.1694, 3.3267])}, {'sensor_id': tensor(3), 'x': tensor([13.0524,  4.3502])}, {'sensor_id': tensor(2), 'x': tensor([15.0693,  3.7658])}, {'sensor_id': tensor(4), 'x': tensor([18.3525,  3.4833])}, {'sensor_id': tensor(1), 'x': tensor([21.6490,  3.9347])}, {'sensor_id': tensor(1), 'x': tensor([24.8167,  4.2799])}, {'sensor_id': tensor(1), 'x': tensor([27.7863,  4.3933])}, {'sensor_id': tensor(3), 'x': tensor([31.1898,  5.5257])}, {'sensor_id': tensor(0), 'x': tensor([34.0032,  4.6109])}, {'sensor_id': tensor(1), 'x': tensor([36.9519,  4.8488])}, {'sensor_id': tensor(4), 'x': tensor([39.6025,  4.7435])}, {'sensor_id': tensor(2), 'x': tensor([42.1560,  5.3400])}, {'sensor_id': tensor(1), 'x': tensor([45.9227,  5.2604])}, {'sensor_id': tensor(2), 'x': tensor([48.3392,  5.6908])}, {'sensor_id': tensor(1), 'x': tensor([52.1634,  5.7445])}, {'sensor_id': tensor(2), 'x': tensor([54.4107,  6.1939])}, {'sensor_id': tensor(0), 'x': tensor([58.2860,  6.3251])}, {'sensor_id': tensor(1), 'x': tensor([61.0124,  6.3153])}, {'sensor_id': tensor(0), 'x': tensor([64.1793,  6.6614])}, {'sensor_id': tensor(2), 'x': tensor([66.3854,  7.0601])}, {'sensor_id': tensor(1), 'x': tensor([70.1047,  6.9807])}, {'sensor_id': tensor(4), 'x': tensor([72.5953,  7.0011])}, {'sensor_id': tensor(2), 'x': tensor([75.1890,  7.5688])}, {'sensor_id': tensor(3), 'x': tensor([78.8799,  8.4907])}, {'sensor_id': tensor(4), 'x': tensor([81.3046,  7.5959])}, {'sensor_id': tensor(3), 'x': tensor([84.7973,  8.9431])}, {'sensor_id': tensor(4), 'x': tensor([87.0585,  8.0343])}, {'sensor_id': tensor(4), 'x': tensor([90.0389,  8.1663])}, {'sensor_id': tensor(2), 'x': tensor([92.8330,  8.5220])}, {'sensor_id': tensor(2), 'x': tensor([95.7760,  8.5050])}, {'sensor_id': tensor(1), 'x': tensor([99.3801,  8.6107])}, {'sensor_id': tensor(4), 'x': tensor([101.9841,   8.5197])}, {'sensor_id': tensor(2), 'x': tensor([104.6606,   9.0728])}, {'sensor_id': tensor(0), 'x': tensor([108.3842,   9.0323])}, {'sensor_id': tensor(3), 'x': tensor([111.4700,  10.0289])}, {'sensor_id': tensor(4), 'x': tensor([113.8042,   9.0392])}, {'sensor_id': tensor(3), 'x': tensor([117.3052,  10.4275])}, {'sensor_id': tensor(1), 'x': tensor([120.0671,   9.6234])}, {'sensor_id': tensor(1), 'x': tensor([123.1322,   9.8111])}, {'sensor_id': tensor(3), 'x': tensor([126.3046,  11.1277])}, {'sensor_id': tensor(1), 'x': tensor([129.0721,  10.3092])}, {'sensor_id': tensor(3), 'x': tensor([132.2044,  11.3628])}, {'sensor_id': tensor(3), 'x': tensor([135.1691,  11.2532])}, {'sensor_id': tensor(0), 'x': tensor([137.9679,  10.5809])}, {'sensor_id': tensor(4), 'x': tensor([140.3839,  10.3766])}, {'sensor_id': tensor(4), 'x': tensor([143.4000,  10.5894])}, {'sensor_id': tensor(4), 'x': tensor([146.2598,  10.9724])}, {'sensor_id': tensor(1), 'x': tensor([149.7123,  11.2845])}, {'sensor_id': tensor(2), 'x': tensor([151.8876,  11.8553])}, {'sensor_id': tensor(3), 'x': tensor([155.7931,  12.8001])}, {'sensor_id': tensor(2), 'x': tensor([157.9830,  12.2561])}, {'sensor_id': tensor(3), 'x': tensor([161.8929,  13.2875])}, {'sensor_id': tensor(1), 'x': tensor([164.7876,  12.5654])}, {'sensor_id': tensor(0), 'x': tensor([167.7211,  12.7872])}, {'sensor_id': tensor(1), 'x': tensor([170.6288,  12.8048])}, {'sensor_id': tensor(4), 'x': tensor([173.3824,  12.8233])}, {'sensor_id': tensor(2), 'x': tensor([176.0866,  13.2088])}, {'sensor_id': tensor(3), 'x': tensor([180.0560,  13.7414])}, {'sensor_id': tensor(1), 'x': tensor([183.0132,  12.9792])}, {'sensor_id': tensor(0), 'x': tensor([186.3090,  13.2550])}, {'sensor_id': tensor(0), 'x': tensor([189.1656,  13.4832])}, {'sensor_id': tensor(3), 'x': tensor([192.3359,  14.3532])}, {'sensor_id': tensor(3), 'x': tensor([195.4426,  14.5637])}, {'sensor_id': tensor(3), 'x': tensor([198.5751,  14.5875])}, {'sensor_id': tensor(2), 'x': tensor([200.6177,  13.9135])}, {'sensor_id': tensor(0), 'x': tensor([204.5692,  13.8697])}, {'sensor_id': tensor(2), 'x': tensor([206.7561,  14.3471])}, {'sensor_id': tensor(0), 'x': tensor([210.5986,  14.2313])}, {'sensor_id': tensor(0), 'x': tensor([213.4642,  14.2828])}, {'sensor_id': tensor(2), 'x': tensor([215.5287,  14.7842])}, {'sensor_id': tensor(3), 'x': tensor([219.3798,  15.7601])}, {'sensor_id': tensor(0), 'x': tensor([222.1944,  15.0777])}, {'sensor_id': tensor(4), 'x': tensor([224.6969,  15.0153])}, {'sensor_id': tensor(4), 'x': tensor([227.7648,  15.1654])}, {'sensor_id': tensor(0), 'x': tensor([231.2411,  15.7304])}, {'sensor_id': tensor(2), 'x': tensor([233.6424,  16.0436])}, {'sensor_id': tensor(2), 'x': tensor([236.7544,  16.1129])}, {'sensor_id': tensor(2), 'x': tensor([239.7679,  16.2487])}, {'sensor_id': tensor(0), 'x': tensor([243.7346,  16.2731])}, {'sensor_id': tensor(1), 'x': tensor([246.5113,  16.3077])}, {'sensor_id': tensor(1), 'x': tensor([249.4129,  16.2574])}, {'sensor_id': tensor(3), 'x': tensor([252.8325,  17.3497])}, {'sensor_id': tensor(2), 'x': tensor([254.7593,  16.7187])}, {'sensor_id': tensor(2), 'x': tensor([257.8399,  16.8686])}, {'sensor_id': tensor(3), 'x': tensor([261.5269,  17.7100])}, {'sensor_id': tensor(0), 'x': tensor([264.4040,  17.1056])}, {'sensor_id': tensor(2), 'x': tensor([266.4769,  17.4210])}, {'sensor_id': tensor(2), 'x': tensor([269.4237,  17.7553])}, {'sensor_id': tensor(4), 'x': tensor([272.7732,  17.5344])}, {'sensor_id': tensor(2), 'x': tensor([275.3050,  17.9998])}, {'sensor_id': tensor(3), 'x': tensor([279.2312,  18.8181])}, {'sensor_id': tensor(1), 'x': tensor([282.0009,  18.1257])}, {'sensor_id': tensor(2), 'x': tensor([284.3007,  18.5558])}, {'sensor_id': tensor(2), 'x': tensor([287.2471,  18.8128])}, {'sensor_id': tensor(0), 'x': tensor([291.1439,  18.9672])}, {'sensor_id': tensor(1), 'x': tensor([293.9634,  19.0506])}, {'sensor_id': tensor(1), 'x': tensor([296.8717,  19.2347])}, {'sensor_id': tensor(2), 'x': tensor([299.0641,  19.7452])}, {'sensor_id': tensor(3), 'x': tensor([303.0298,  20.6010])}, {'sensor_id': tensor(3), 'x': tensor([305.9593,  20.7961])}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-bd4b431448aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0minterpretation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mreinterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-fb528cd99f78>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(track)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# outputs shape 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_sensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#  [sensor_ids]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mdebiased_observations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrack\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;31m#     debiased_observations = biased_observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# this indexing pattern is not implemented to sub into a Gaussian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Uber/funsor/funsor/terms.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBinary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_funsor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pyro3/lib/python3.6/site-packages/multipledispatch/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMDNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Uber/funsor/funsor/terms.py\u001b[0m in \u001b[0;36mto_funsor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mraises\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \"\"\"\n\u001b[0;32m--> 724\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot convert to Funsor: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert to Funsor: [{'sensor_id': tensor(2), 'x': tensor([9.1694, 3.3267])}, {'sensor_id': tensor(3), 'x': tensor([13.0524,  4.3502])}, {'sensor_id': tensor(2), 'x': tensor([15.0693,  3.7658])}, {'sensor_id': tensor(4), 'x': tensor([18.3525,  3.4833])}, {'sensor_id': tensor(1), 'x': tensor([21.6490,  3.9347])}, {'sensor_id': tensor(1), 'x': tensor([24.8167,  4.2799])}, {'sensor_id': tensor(1), 'x': tensor([27.7863,  4.3933])}, {'sensor_id': tensor(3), 'x': tensor([31.1898,  5.5257])}, {'sensor_id': tensor(0), 'x': tensor([34.0032,  4.6109])}, {'sensor_id': tensor(1), 'x': tensor([36.9519,  4.8488])}, {'sensor_id': tensor(4), 'x': tensor([39.6025,  4.7435])}, {'sensor_id': tensor(2), 'x': tensor([42.1560,  5.3400])}, {'sensor_id': tensor(1), 'x': tensor([45.9227,  5.2604])}, {'sensor_id': tensor(2), 'x': tensor([48.3392,  5.6908])}, {'sensor_id': tensor(1), 'x': tensor([52.1634,  5.7445])}, {'sensor_id': tensor(2), 'x': tensor([54.4107,  6.1939])}, {'sensor_id': tensor(0), 'x': tensor([58.2860,  6.3251])}, {'sensor_id': tensor(1), 'x': tensor([61.0124,  6.3153])}, {'sensor_id': tensor(0), 'x': tensor([64.1793,  6.6614])}, {'sensor_id': tensor(2), 'x': tensor([66.3854,  7.0601])}, {'sensor_id': tensor(1), 'x': tensor([70.1047,  6.9807])}, {'sensor_id': tensor(4), 'x': tensor([72.5953,  7.0011])}, {'sensor_id': tensor(2), 'x': tensor([75.1890,  7.5688])}, {'sensor_id': tensor(3), 'x': tensor([78.8799,  8.4907])}, {'sensor_id': tensor(4), 'x': tensor([81.3046,  7.5959])}, {'sensor_id': tensor(3), 'x': tensor([84.7973,  8.9431])}, {'sensor_id': tensor(4), 'x': tensor([87.0585,  8.0343])}, {'sensor_id': tensor(4), 'x': tensor([90.0389,  8.1663])}, {'sensor_id': tensor(2), 'x': tensor([92.8330,  8.5220])}, {'sensor_id': tensor(2), 'x': tensor([95.7760,  8.5050])}, {'sensor_id': tensor(1), 'x': tensor([99.3801,  8.6107])}, {'sensor_id': tensor(4), 'x': tensor([101.9841,   8.5197])}, {'sensor_id': tensor(2), 'x': tensor([104.6606,   9.0728])}, {'sensor_id': tensor(0), 'x': tensor([108.3842,   9.0323])}, {'sensor_id': tensor(3), 'x': tensor([111.4700,  10.0289])}, {'sensor_id': tensor(4), 'x': tensor([113.8042,   9.0392])}, {'sensor_id': tensor(3), 'x': tensor([117.3052,  10.4275])}, {'sensor_id': tensor(1), 'x': tensor([120.0671,   9.6234])}, {'sensor_id': tensor(1), 'x': tensor([123.1322,   9.8111])}, {'sensor_id': tensor(3), 'x': tensor([126.3046,  11.1277])}, {'sensor_id': tensor(1), 'x': tensor([129.0721,  10.3092])}, {'sensor_id': tensor(3), 'x': tensor([132.2044,  11.3628])}, {'sensor_id': tensor(3), 'x': tensor([135.1691,  11.2532])}, {'sensor_id': tensor(0), 'x': tensor([137.9679,  10.5809])}, {'sensor_id': tensor(4), 'x': tensor([140.3839,  10.3766])}, {'sensor_id': tensor(4), 'x': tensor([143.4000,  10.5894])}, {'sensor_id': tensor(4), 'x': tensor([146.2598,  10.9724])}, {'sensor_id': tensor(1), 'x': tensor([149.7123,  11.2845])}, {'sensor_id': tensor(2), 'x': tensor([151.8876,  11.8553])}, {'sensor_id': tensor(3), 'x': tensor([155.7931,  12.8001])}, {'sensor_id': tensor(2), 'x': tensor([157.9830,  12.2561])}, {'sensor_id': tensor(3), 'x': tensor([161.8929,  13.2875])}, {'sensor_id': tensor(1), 'x': tensor([164.7876,  12.5654])}, {'sensor_id': tensor(0), 'x': tensor([167.7211,  12.7872])}, {'sensor_id': tensor(1), 'x': tensor([170.6288,  12.8048])}, {'sensor_id': tensor(4), 'x': tensor([173.3824,  12.8233])}, {'sensor_id': tensor(2), 'x': tensor([176.0866,  13.2088])}, {'sensor_id': tensor(3), 'x': tensor([180.0560,  13.7414])}, {'sensor_id': tensor(1), 'x': tensor([183.0132,  12.9792])}, {'sensor_id': tensor(0), 'x': tensor([186.3090,  13.2550])}, {'sensor_id': tensor(0), 'x': tensor([189.1656,  13.4832])}, {'sensor_id': tensor(3), 'x': tensor([192.3359,  14.3532])}, {'sensor_id': tensor(3), 'x': tensor([195.4426,  14.5637])}, {'sensor_id': tensor(3), 'x': tensor([198.5751,  14.5875])}, {'sensor_id': tensor(2), 'x': tensor([200.6177,  13.9135])}, {'sensor_id': tensor(0), 'x': tensor([204.5692,  13.8697])}, {'sensor_id': tensor(2), 'x': tensor([206.7561,  14.3471])}, {'sensor_id': tensor(0), 'x': tensor([210.5986,  14.2313])}, {'sensor_id': tensor(0), 'x': tensor([213.4642,  14.2828])}, {'sensor_id': tensor(2), 'x': tensor([215.5287,  14.7842])}, {'sensor_id': tensor(3), 'x': tensor([219.3798,  15.7601])}, {'sensor_id': tensor(0), 'x': tensor([222.1944,  15.0777])}, {'sensor_id': tensor(4), 'x': tensor([224.6969,  15.0153])}, {'sensor_id': tensor(4), 'x': tensor([227.7648,  15.1654])}, {'sensor_id': tensor(0), 'x': tensor([231.2411,  15.7304])}, {'sensor_id': tensor(2), 'x': tensor([233.6424,  16.0436])}, {'sensor_id': tensor(2), 'x': tensor([236.7544,  16.1129])}, {'sensor_id': tensor(2), 'x': tensor([239.7679,  16.2487])}, {'sensor_id': tensor(0), 'x': tensor([243.7346,  16.2731])}, {'sensor_id': tensor(1), 'x': tensor([246.5113,  16.3077])}, {'sensor_id': tensor(1), 'x': tensor([249.4129,  16.2574])}, {'sensor_id': tensor(3), 'x': tensor([252.8325,  17.3497])}, {'sensor_id': tensor(2), 'x': tensor([254.7593,  16.7187])}, {'sensor_id': tensor(2), 'x': tensor([257.8399,  16.8686])}, {'sensor_id': tensor(3), 'x': tensor([261.5269,  17.7100])}, {'sensor_id': tensor(0), 'x': tensor([264.4040,  17.1056])}, {'sensor_id': tensor(2), 'x': tensor([266.4769,  17.4210])}, {'sensor_id': tensor(2), 'x': tensor([269.4237,  17.7553])}, {'sensor_id': tensor(4), 'x': tensor([272.7732,  17.5344])}, {'sensor_id': tensor(2), 'x': tensor([275.3050,  17.9998])}, {'sensor_id': tensor(3), 'x': tensor([279.2312,  18.8181])}, {'sensor_id': tensor(1), 'x': tensor([282.0009,  18.1257])}, {'sensor_id': tensor(2), 'x': tensor([284.3007,  18.5558])}, {'sensor_id': tensor(2), 'x': tensor([287.2471,  18.8128])}, {'sensor_id': tensor(0), 'x': tensor([291.1439,  18.9672])}, {'sensor_id': tensor(1), 'x': tensor([293.9634,  19.0506])}, {'sensor_id': tensor(1), 'x': tensor([296.8717,  19.2347])}, {'sensor_id': tensor(2), 'x': tensor([299.0641,  19.7452])}, {'sensor_id': tensor(3), 'x': tensor([303.0298,  20.6010])}, {'sensor_id': tensor(3), 'x': tensor([305.9593,  20.7961])}]"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "params = [bias_scales]\n",
    "# params.append(transition_matrix)\n",
    "optim = Adam(params, lr=1e-3)\n",
    "model = HMM(num_sensors)\n",
    "for i in range(num_epochs):\n",
    "    optim.zero_grad()\n",
    "    with interpretation(lazy):\n",
    "        log_prob = apply_optimizer(model(partial_obs))\n",
    "    loss = -reinterpret(log_prob).data\n",
    "    loss.backward()\n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "    optim.step()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the joint posterior distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### possible plots\n",
    "1. plot the MSE of the MAP estimates with and without bias (or table)\n",
    "2. train with and without marginalizing out bias, plot both loss curves\n",
    "  - plot nll and MSE at each epoch\n",
    "3. smoothing? would require adjoint algorithm `tests/test_adjoint.py`\n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
