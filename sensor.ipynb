{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Sensor Bias\n",
    "\n",
    "We want to compute the joint posterior over sensors' biases in a 2-D tracking setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import funsor\n",
    "import funsor.pyro\n",
    "import funsor.distributions as f_dist\n",
    "import funsor.ops as ops\n",
    "from funsor.pyro.convert import dist_to_funsor, mvn_to_funsor, matrix_and_mvn_to_funsor, tensor_to_funsor\n",
    "from funsor.interpreter import interpretation, reinterpret\n",
    "from funsor.optimizer import apply_optimizer\n",
    "from funsor.terms import lazy\n",
    "from funsor.domains import bint, reals\n",
    "from funsor.torch import Tensor, Variable\n",
    "from funsor.sum_product import sequential_sum_product\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate some synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sensors = 5\n",
    "num_frames = 100\n",
    "\n",
    "# simulate biased sensors\n",
    "sensors  = []\n",
    "for _ in range(num_sensors):\n",
    "    bias = 0.5 * torch.randn(2)\n",
    "    sensors.append(bias)\n",
    "\n",
    "# simulate a single track\n",
    "track = []\n",
    "z = 10 * torch.rand(2)  # initial state\n",
    "v = 2 * torch.randn(2)  # velocity\n",
    "for t in range(num_frames):\n",
    "    # Advance latent state.\n",
    "    z += v + 0.1 * torch.randn(2)\n",
    "#     z.clamp_(min=0, max=10)  # keep in the box\n",
    "    \n",
    "    # Observe via a random sensor.\n",
    "    sensor_id = pyro.sample('id', dist.Categorical(torch.ones(num_sensors)))\n",
    "    x = z - sensors[sensor_id]\n",
    "    track.append({\"sensor_id\": sensor_id, \"x\": x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up a tracking problem in Funsor. We start by modeling the biases of each sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add_(): argument 'other' (position 1) must be Tensor, not Joint",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2f54c54f7649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         real_inputs=OrderedDict([(\"bias_{}\".format(i), reals(2))])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mreal_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     )(value=\"bias_{}\".format(i))\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mbias_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: add_(): argument 'other' (position 1) must be Tensor, not Joint"
     ]
    }
   ],
   "source": [
    "# TODO transform this to cholesky decomposition\n",
    "# print(bias_cov.shape)\n",
    "# bias_cov = bias_cov @ bias_cov.t()\n",
    "# create a joint Gaussian over biases\n",
    "\n",
    "# covs = [torch.eye(2, requires_grad=True) for i in range(num_sensors)]\n",
    "# bias_dist = 0.\n",
    "# for i in range(num_sensors):\n",
    "#     bias += funsor.pyro.convert.mvn_to_funsor(\n",
    "#         dist.MultivariateNormal(torch.zeros(2), covs[i]),\n",
    "# #         event_dims=(\"pos\",),\n",
    "# #         real_inputs=OrderedDict([(\"bias_{}\".format(i), reals(2))])\n",
    "#         real_inputs=OrderedDict([(\"bias\", reals(2))])\n",
    "#     )(value=\"bias_{}\".format(i))\n",
    "# bias_dist.__dict__\n",
    "\n",
    "bias_scales = torch.ones(2, requires_grad=True)  # This can be learned\n",
    "bias_dist = funsor.pyro.convert.mvn_to_funsor(\n",
    "    dist.MultivariateNormal(\n",
    "        torch.zeros(num_sensors * 2),\n",
    "        bias_scales.expand(num_sensors, 2).reshape(-1).diag_embed()\n",
    "    ),\n",
    "    real_inputs=OrderedDict(bias=reals(num_sensors, 2))\n",
    ")\n",
    "bias_dist.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the filter in funsor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace as bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# this can be parameterized by a lower dimensional vector \n",
    "# to learn a structured transition matrix\n",
    "# eg a GP with a matern v=3/2 kernel\n",
    "# see paper for details \n",
    "transition_matrix = torch.randn(2, 2, requires_grad=True)\n",
    "\n",
    "def model(track):\n",
    "    init_dist = torch.distributions.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "\n",
    "    transition_dist = torch.distributions.MultivariateNormal(\n",
    "        torch.zeros(2),\n",
    "        torch.eye(2))\n",
    "    observation_matrix = torch.eye(2) + 0.2 * torch.randn(2, 2)\n",
    "    observation_dist = torch.distributions.MultivariateNormal(\n",
    "        torch.zeros(2),\n",
    "        torch.eye(2))\n",
    "\n",
    "    init = dist_to_funsor(init_dist)(value=\"state\")\n",
    "    # inputs are the previous state ``state`` and the next state\n",
    "    trans = matrix_and_mvn_to_funsor(transition_matrix, transition_dist,\n",
    "                                     (\"time\",), \"state\", \"state(time=1)\")\n",
    "    obs = matrix_and_mvn_to_funsor(observation_matrix, observation_dist,\n",
    "                                   (\"time\",), \"state(time=1)\", \"value\")\n",
    "    \n",
    "    # Now this is the crux, we add bias to the observation\n",
    "    sensor_ids = Tensor(\n",
    "        torch.tensor([frame[\"sensor_id\"] for frame in track]),\n",
    "        OrderedDict([(\"time\", bint(num_frames))]),\n",
    "        dtype=len(sensors)\n",
    "    )\n",
    "    biased_observations = Tensor(\n",
    "        torch.stack([frame[\"x\"] for frame in track]),\n",
    "        OrderedDict([(\"time\", bint(num_frames))])\n",
    "    )\n",
    "    \n",
    "    # incorporate sensor id in the observation\n",
    "#     bias_over_time = bias(value=sensor_ids)\n",
    "    # bias_over_time = bias(bias=biased_observations)\n",
    "    # inputs: bias shape (num_sensors, 2), sensor_ids\n",
    "    # outputs: 2\n",
    "    bias = Variable(\"bias\", reals(num_sensors, 2))[sensor_ids]\n",
    "    \n",
    "    debiased_observations = biased_observations - bias\n",
    "    obs = obs(value=debiased_observations)\n",
    "#     print(obs)\n",
    "    # Similar to funsor.pyro.hmm.GaussianHMM.log_prob()\n",
    "    # ndims = max(len(batch_shape), value.dim() - event_dim)\n",
    "    # value = tensor_to_funsor(value, (\"time\",), event_output=event_dim - 1,\n",
    "    #                          dtype=self.dtype)\n",
    "\n",
    "    # obs = obs(value=value)\n",
    "    logp = trans + obs + bias_dist\n",
    "\n",
    "    bb()\n",
    "    # collapse out the time variable\n",
    "    # TODO this can only handle homogeneous funsor types\n",
    "    logp = sequential_sum_product(ops.logaddexp, ops.add,\n",
    "                                  logp, \"time\", {\"state\": \"state(time=1)\"})\n",
    "    logp += init\n",
    "    # logaddexp across all states\n",
    "    logp = logp.reduce(ops.logaddexp, frozenset([\"state\", \"state(time=1)\"]))\n",
    "#     # ensure we collapsed out the right dim\n",
    "#     assert logp.data.dim() == 0\n",
    "    return logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Finally we have a result that is a joint Gaussian over the biases.\n",
    "We can\n",
    "1. optimize all parameters to maximize `result`\n",
    "2. estimate the joint distribution over all bias parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary(add, tensor(-1.8379), Subs(Gaussian(tensor([-0., -0., 0., 0.]), tensor([[ 1.1097,  0.2558, -1.0271, -0.2338],\n",
      "        [ 0.2558,  1.1462, -0.0053, -1.0706],\n",
      "        [-1.0271, -0.0053,  1.0000,  0.0000],\n",
      "        [-0.2338, -1.0706,  0.0000,  1.0000]]), (('state(time=1)', reals(2,)), ('value__BOUND_11', reals(2,)))), (('value__BOUND_11', (Tensor(tensor([[ 1.1772e+00,  6.3812e+00],\n",
      "        [ 5.4286e-01,  5.9874e+00],\n",
      "        [ 3.1372e-02,  5.5602e+00],\n",
      "        [-7.6038e-01,  4.8189e+00],\n",
      "        [-1.0087e+00,  4.8406e+00],\n",
      "        [-1.1114e+00,  3.6553e+00],\n",
      "        [-1.1761e+00,  3.6058e+00],\n",
      "        [-2.8492e+00,  3.6637e+00],\n",
      "        [-3.2419e+00,  2.9562e+00],\n",
      "        [-3.9508e+00,  2.9224e+00],\n",
      "        [-3.8815e+00,  1.6666e+00],\n",
      "        [-5.0028e+00,  2.2088e+00],\n",
      "        [-4.5916e+00,  1.1623e+00],\n",
      "        [-5.1752e+00,  9.6112e-01],\n",
      "        [-6.1943e+00,  1.9290e-01],\n",
      "        [-6.7214e+00, -9.9259e-02],\n",
      "        [-7.7270e+00,  4.9325e-01],\n",
      "        [-8.2083e+00, -1.0520e-01],\n",
      "        [-7.9595e+00, -8.4162e-01],\n",
      "        [-8.9078e+00, -1.6937e+00],\n",
      "        [-1.0096e+01, -1.2040e+00],\n",
      "        [-1.0432e+01, -1.6837e+00],\n",
      "        [-1.0761e+01, -2.2873e+00],\n",
      "        [-1.1110e+01, -3.4412e+00],\n",
      "        [-1.1758e+01, -3.7194e+00],\n",
      "        [-1.1907e+01, -3.6610e+00],\n",
      "        [-1.2367e+01, -3.9982e+00],\n",
      "        [-1.3798e+01, -4.3946e+00],\n",
      "        [-1.4279e+01, -4.6955e+00],\n",
      "        [-1.4572e+01, -4.7973e+00],\n",
      "        [-1.4844e+01, -5.8561e+00],\n",
      "        [-1.5233e+01, -6.2878e+00],\n",
      "        [-1.5698e+01, -6.6591e+00],\n",
      "        [-1.6370e+01, -6.2784e+00],\n",
      "        [-1.7239e+01, -6.5357e+00],\n",
      "        [-1.6913e+01, -7.4172e+00],\n",
      "        [-1.8481e+01, -7.9062e+00],\n",
      "        [-1.8570e+01, -8.7914e+00],\n",
      "        [-1.9261e+01, -8.3013e+00],\n",
      "        [-2.0021e+01, -8.5986e+00],\n",
      "        [-2.0209e+01, -9.1084e+00],\n",
      "        [-2.0972e+01, -9.7381e+00],\n",
      "        [-2.1587e+01, -9.9494e+00],\n",
      "        [-2.1145e+01, -1.0451e+01],\n",
      "        [-2.2848e+01, -1.0681e+01],\n",
      "        [-2.3198e+01, -1.1231e+01],\n",
      "        [-2.4048e+01, -1.1734e+01],\n",
      "        [-2.4341e+01, -1.1763e+01],\n",
      "        [-2.4739e+01, -1.3085e+01],\n",
      "        [-2.5201e+01, -1.3413e+01],\n",
      "        [-2.6156e+01, -1.3000e+01],\n",
      "        [-2.6599e+01, -1.4264e+01],\n",
      "        [-2.7372e+01, -1.4731e+01],\n",
      "        [-2.8010e+01, -1.5129e+01],\n",
      "        [-2.9093e+01, -1.4587e+01],\n",
      "        [-2.9625e+01, -1.4815e+01],\n",
      "        [-3.0101e+01, -1.5308e+01],\n",
      "        [-2.9755e+01, -1.5987e+01],\n",
      "        [-3.1196e+01, -1.6228e+01],\n",
      "        [-3.0821e+01, -1.6485e+01],\n",
      "        [-3.1943e+01, -1.6473e+01],\n",
      "        [-3.2621e+01, -1.7264e+01],\n",
      "        [-3.3261e+01, -1.7146e+01],\n",
      "        [-3.3838e+01, -1.8041e+01],\n",
      "        [-3.3325e+01, -1.8454e+01],\n",
      "        [-3.3738e+01, -1.8857e+01],\n",
      "        [-3.4135e+01, -1.9260e+01],\n",
      "        [-3.5124e+01, -2.0183e+01],\n",
      "        [-3.5925e+01, -1.9864e+01],\n",
      "        [-3.6317e+01, -2.0142e+01],\n",
      "        [-3.7224e+01, -2.0466e+01],\n",
      "        [-3.7771e+01, -2.1188e+01],\n",
      "        [-3.8319e+01, -2.1280e+01],\n",
      "        [-3.7970e+01, -2.2070e+01],\n",
      "        [-3.8457e+01, -2.2479e+01],\n",
      "        [-3.9441e+01, -2.3178e+01],\n",
      "        [-4.0334e+01, -2.2722e+01],\n",
      "        [-4.0766e+01, -2.3070e+01],\n",
      "        [-4.0550e+01, -2.3806e+01],\n",
      "        [-4.2099e+01, -2.4128e+01],\n",
      "        [-4.2353e+01, -2.4199e+01],\n",
      "        [-4.2738e+01, -2.5321e+01],\n",
      "        [-4.3448e+01, -2.5663e+01],\n",
      "        [-4.3855e+01, -2.6250e+01],\n",
      "        [-4.4871e+01, -2.6100e+01],\n",
      "        [-4.4965e+01, -2.6176e+01],\n",
      "        [-4.5203e+01, -2.7496e+01],\n",
      "        [-4.6286e+01, -2.6745e+01],\n",
      "        [-4.6001e+01, -2.7385e+01],\n",
      "        [-4.7452e+01, -2.7544e+01],\n",
      "        [-4.7513e+01, -2.8409e+01],\n",
      "        [-4.8308e+01, -2.7960e+01],\n",
      "        [-4.8811e+01, -2.8231e+01],\n",
      "        [-4.9186e+01, -2.9441e+01],\n",
      "        [-5.0266e+01, -2.8945e+01],\n",
      "        [-5.0839e+01, -2.9276e+01],\n",
      "        [-5.1138e+01, -3.0053e+01],\n",
      "        [-5.0693e+01, -3.0474e+01],\n",
      "        [-5.2288e+01, -3.0745e+01],\n",
      "        [-5.1883e+01, -3.1294e+01]]), OrderedDict([('time', bint(100))])) - Binary(GetitemOp(0), bias, Tensor(tensor([1, 1, 1, 2, 1, 0, 4, 3, 2, 3, 0, 3, 4, 4, 0, 0, 3, 1, 4, 0, 3, 1, 1, 0,\n",
      "        0, 4, 4, 2, 2, 1, 0, 0, 0, 1, 3, 4, 2, 0, 1, 3, 1, 2, 2, 4, 2, 2, 2, 1,\n",
      "        0, 0, 1, 0, 0, 0, 3, 3, 3, 4, 2, 4, 1, 2, 3, 2, 4, 4, 4, 0, 1, 1, 3, 2,\n",
      "        3, 4, 4, 0, 3, 1, 4, 2, 1, 0, 0, 0, 2, 1, 0, 3, 4, 2, 0, 1, 1, 0, 3, 3,\n",
      "        2, 4, 2, 4]), OrderedDict([('time', bint(100))]), 5)))),)))\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "TODO",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-96586a3b61c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0minterpretation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mreinterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-d27f34b8e7e9>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(track)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# collapse out the time variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     logp = sequential_sum_product(ops.logaddexp, ops.add,\n\u001b[0;32m---> 57\u001b[0;31m                                   logp, \"time\", {\"state\": \"state(time=1)\"})\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mlogp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# logaddexp across all states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Uber/funsor/funsor/sum_product.py\u001b[0m in \u001b[0;36msequential_sum_product\u001b[0;34m(sum_op, prod_op, trans, time, step)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mduration\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0meven_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mextra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSlice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mcontracted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontracted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontracted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Uber/funsor/funsor/sum_product.py\u001b[0m in \u001b[0;36mCat\u001b[0;34m(parts, name)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TODO\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: TODO"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "params = covs.copy()\n",
    "params.append(transition_matrix)\n",
    "optim = Adam(params, lr=1e-3)\n",
    "for i in range(num_epochs):\n",
    "    optim.zero_grad()\n",
    "    with interpretation(lazy):\n",
    "        log_prob = apply_optimizer(model(track))\n",
    "    loss = -reinterpret(log_prob).data\n",
    "    loss.backward()\n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "    optim.step()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the joint posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
