{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Sensor Bias\n",
    "\n",
    "We want to compute the joint posterior over sensors' biases in a 2-D tracking setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import funsor\n",
    "import funsor.pyro\n",
    "import funsor.distributions as f_dist\n",
    "import funsor.ops as ops\n",
    "from funsor.pyro.convert import dist_to_funsor, mvn_to_funsor, matrix_and_mvn_to_funsor, tensor_to_funsor\n",
    "from funsor.interpreter import interpretation, reinterpret\n",
    "from funsor.optimizer import apply_optimizer\n",
    "from funsor.terms import lazy\n",
    "from funsor.domains import bint, reals\n",
    "from funsor.sum_product import sequential_sum_product\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate some synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sensors = 5\n",
    "num_frames = 100\n",
    "\n",
    "# simulate biased sensors\n",
    "sensors  = []\n",
    "for _ in range(num_sensors):\n",
    "    bias = 0.5 * torch.randn(2)\n",
    "    sensors.append(bias)\n",
    "\n",
    "# simulate a single track\n",
    "track = []\n",
    "z = 10 * torch.rand(2)  # initial state\n",
    "v = 2 * torch.randn(2)  # velocity\n",
    "for t in range(num_frames):\n",
    "    # Advance latent state.\n",
    "    z += v + 0.1 * torch.randn(2)\n",
    "#     z.clamp_(min=0, max=10)  # keep in the box\n",
    "    \n",
    "    # Observe via a random sensor.\n",
    "    sensor_id = pyro.sample('id', dist.Categorical(torch.ones(num_sensors)))\n",
    "    x = z - sensors[sensor_id]\n",
    "    track.append({\"sensor_id\": sensor_id, \"x\": x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up a tracking problem in Funsor. We start by modeling the biases of each sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': OrderedDict([('bias_0', reals(2,)),\n",
       "              ('bias_1', reals(2,)),\n",
       "              ('bias_2', reals(2,)),\n",
       "              ('bias_3', reals(2,)),\n",
       "              ('bias_4', reals(2,))]),\n",
       " 'output': reals(),\n",
       " 'fresh': frozenset(),\n",
       " 'bound': frozenset(),\n",
       " 'deltas': (),\n",
       " 'discrete': Tensor(-9.189385414123535, OrderedDict(), 'real'),\n",
       " 'gaussian': Gaussian(..., ((bias_0, reals(2,)), (bias_1, reals(2,)), (bias_2, reals(2,)), (bias_3, reals(2,)), (bias_4, reals(2,)),)),\n",
       " '_ast_values': ((),\n",
       "  Tensor(-9.189385414123535, OrderedDict(), 'real'),\n",
       "  Gaussian(..., ((bias_0, reals(2,)), (bias_1, reals(2,)), (bias_2, reals(2,)), (bias_3, reals(2,)), (bias_4, reals(2,)),)))}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO transform this to cholesky decomposition\n",
    "# print(bias_cov.shape)\n",
    "# bias_cov = bias_cov @ bias_cov.t()\n",
    "# create a joint Gaussian over biases\n",
    "covs = [torch.eye(2, requires_grad=True) for i in range(num_sensors)]\n",
    "bias = 0.\n",
    "for i in range(num_sensors):\n",
    "    bias += funsor.pyro.convert.mvn_to_funsor(\n",
    "        dist.MultivariateNormal(torch.zeros(2), covs[i]),\n",
    "        event_dims=(\"pos\",),\n",
    "        real_inputs=OrderedDict([(\"bias_{}\".format(i), reals(2))])\n",
    "    )(value=\"bias_{}\".format(i))\n",
    "bias.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "# bias = sum(\n",
    "#     funsor.pyro.convert.mvn_to_funsor(\n",
    "#         dist.MultivariateNormal(\n",
    "#             torch.zeros(2),\n",
    "#             torch.eye(2, requires_grad=True)  # This can be learned\n",
    "#         )\n",
    "#     )(value=\"bias_{}\".format(i))\n",
    "#     for i in range(num_sensors)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the filter in funsor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace as bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(track):\n",
    "    init_dist = torch.distributions.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "    # TODO\n",
    "    # this can be parameterized by a lower dimensional vector \n",
    "    # to learn a structured transition matrix\n",
    "    # eg a GP with a matern v=3/2 kernel\n",
    "    # see paper for details \n",
    "    transition_matrix = torch.randn(2, 2, requires_grad=True)\n",
    "\n",
    "    transition_dist = torch.distributions.MultivariateNormal(\n",
    "        torch.zeros(2),\n",
    "        torch.eye(2))\n",
    "    observation_matrix = torch.eye(2) + 0.2 * torch.randn(2, 2)\n",
    "    observation_dist = torch.distributions.MultivariateNormal(\n",
    "        torch.zeros(2),\n",
    "        torch.eye(2))\n",
    "\n",
    "    init = dist_to_funsor(init_dist)(value=\"state\")\n",
    "    # inputs are the previous state ``state`` and the next state\n",
    "    trans = matrix_and_mvn_to_funsor(transition_matrix, transition_dist,\n",
    "                                     (\"time\",), \"state\", \"state(time=1)\")\n",
    "    obs = matrix_and_mvn_to_funsor(observation_matrix, observation_dist,\n",
    "                                   (\"time\",), \"state(time=1)\", \"value\")\n",
    "    \n",
    "    # Now this is the crux, we add bias to the observation\n",
    "    sensor_ids = funsor.torch.Tensor(\n",
    "        torch.tensor([frame[\"sensor_id\"] for frame in track]),\n",
    "        OrderedDict([(\"sensor_id\", bint(num_frames))]),\n",
    "        dtype=len(sensors)\n",
    "    )\n",
    "    biased_observations = funsor.torch.Tensor(\n",
    "        torch.stack([frame[\"x\"] for frame in track]),\n",
    "        OrderedDict([(\"value\", bint(num_frames))])\n",
    "    )\n",
    "    bias_over_time = bias(sensor_id=sensor_ids)\n",
    "    obs = obs(value=biased_observations)\n",
    "    # Similar to funsor.pyro.hmm.GaussianHMM.log_prob()\n",
    "    # ndims = max(len(batch_shape), value.dim() - event_dim)\n",
    "    # value = tensor_to_funsor(value, (\"time\",), event_output=event_dim - 1,\n",
    "    #                          dtype=self.dtype)\n",
    "\n",
    "    # obs = obs(value=value)\n",
    "    result = trans + obs\n",
    "    bb()\n",
    "\n",
    "    result = sequential_sum_product(ops.logaddexp, ops.add,\n",
    "                                    result, \"time\", {\"state\": \"state(time=1)\"})\n",
    "    result += init\n",
    "    result = result.reduce(ops.logaddexp, frozenset([\"state\", \"state(time=1)\"]))\n",
    "    import pdb; pdb.set_trace()\n",
    "    # ensure we collapsed out the right dim\n",
    "    assert result.data.dim() == 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Finally we have a result that is a joint Gaussian over the biases.\n",
    "We can\n",
    "1. optimize all parameters to maximize `result.reduce(obs.logaddexp)`\n",
    "2. estimate the joint distribution over all bias parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-24-1e9bee2b04b4>(47)model()\n",
      "-> result = sequential_sum_product(ops.logaddexp, ops.add,\n",
      "(Pdb) obs\n",
      "(tensor(-1.8379) + Binary(add, Gaussian(tensor([[  0.1201,   0.1777],\n",
      "        [  0.6589,  -0.7249],\n",
      "        [  1.3408,  -1.5653],\n",
      "        [  1.7657,  -2.4050],\n",
      "        [  2.6114,  -3.7786],\n",
      "        [  2.6402,  -4.1607],\n",
      "        [  4.0417,  -6.0849],\n",
      "        [  4.9014,  -6.8800],\n",
      "        [  4.3693,  -6.9827],\n",
      "        [  4.9077,  -7.8910],\n",
      "        [  6.6962,  -9.7206],\n",
      "        [  5.9895,  -9.7265],\n",
      "        [  7.7263, -11.5969],\n",
      "        [  7.2662, -11.5610],\n",
      "        [  8.2741, -13.0112],\n",
      "        [  8.2353, -13.3633],\n",
      "        [  9.9671, -15.1411],\n",
      "        [  9.3980, -15.0463],\n",
      "        [ 10.0467, -16.0316],\n",
      "        [ 11.1821, -17.4374],\n",
      "        [ 11.9551, -18.8577],\n",
      "        [ 12.2221, -19.1618],\n",
      "        [ 12.8748, -20.1079],\n",
      "        [ 13.8583, -21.3181],\n",
      "        [ 13.3654, -21.3223],\n",
      "        [ 13.8316, -22.1995],\n",
      "        [ 15.2072, -24.0708],\n",
      "        [ 15.9629, -24.7447],\n",
      "        [ 16.0750, -25.6653],\n",
      "        [ 15.7817, -25.3953],\n",
      "        [ 16.4457, -26.7100],\n",
      "        [ 16.6000, -27.1185],\n",
      "        [ 17.1204, -28.0705],\n",
      "        [ 17.5263, -28.9862],\n",
      "        [ 18.5423, -30.4235],\n",
      "        [ 19.7802, -31.7246],\n",
      "        [ 19.8664, -32.7350],\n",
      "        [ 19.4812, -32.4861],\n",
      "        [ 20.6691, -33.9616],\n",
      "        [ 21.9305, -35.3124],\n",
      "        [ 21.5252, -35.3530],\n",
      "        [ 22.5021, -36.7147],\n",
      "        [ 22.5520, -37.1718],\n",
      "        [ 23.7217, -39.0317],\n",
      "        [ 23.6868, -38.9558],\n",
      "        [ 24.1251, -39.8683],\n",
      "        [ 24.9788, -41.2412],\n",
      "        [ 26.2134, -42.5185],\n",
      "        [ 25.5847, -42.5904],\n",
      "        [ 26.5523, -43.8690],\n",
      "        [ 26.6308, -44.1600],\n",
      "        [ 27.2075, -45.0749],\n",
      "        [ 27.6514, -45.9536],\n",
      "        [ 29.1125, -47.7306],\n",
      "        [ 29.6337, -48.8097],\n",
      "        [ 29.8787, -49.2667],\n",
      "        [ 31.1048, -50.4815],\n",
      "        [ 30.5409, -50.4511],\n",
      "        [ 31.6584, -52.4355],\n",
      "        [ 31.8604, -52.7913],\n",
      "        [ 32.9910, -53.9548],\n",
      "        [ 32.6885, -53.9775],\n",
      "        [ 33.3714, -55.3313],\n",
      "        [ 33.4656, -55.8239],\n",
      "        [ 34.4221, -57.3104],\n",
      "        [ 34.8828, -58.1613],\n",
      "        [ 35.8391, -59.3760],\n",
      "        [ 35.3075, -59.4149],\n",
      "        [ 36.5363, -61.2702],\n",
      "        [ 36.5643, -61.1485],\n",
      "        [ 38.2841, -62.8208],\n",
      "        [ 38.4944, -63.9187],\n",
      "        [ 38.6998, -64.1553],\n",
      "        [ 38.8003, -64.5500],\n",
      "        [ 40.0587, -66.4864],\n",
      "        [ 40.7042, -67.4378],\n",
      "        [ 40.7985, -67.7767],\n",
      "        [ 40.8535, -68.1441],\n",
      "        [ 41.5144, -69.0252],\n",
      "        [ 42.2697, -70.4035],\n",
      "        [ 43.1500, -71.7334],\n",
      "        [ 43.9693, -72.4309],\n",
      "        [ 43.4990, -72.5165],\n",
      "        [ 43.9444, -73.3692],\n",
      "        [ 44.5730, -74.2605],\n",
      "        [ 45.4551, -75.6091],\n",
      "        [ 46.1275, -77.0059],\n",
      "        [ 46.4598, -77.8478],\n",
      "        [ 47.2812, -78.6730],\n",
      "        [ 46.7472, -78.7659],\n",
      "        [ 48.5377, -80.6221],\n",
      "        [ 48.5774, -81.7132],\n",
      "        [ 49.3933, -82.4750],\n",
      "        [ 49.0068, -82.5583],\n",
      "        [ 49.9935, -83.9593],\n",
      "        [ 49.8789, -84.3249],\n",
      "        [ 51.4957, -86.0971],\n",
      "        [ 50.9004, -86.1255],\n",
      "        [ 51.2953, -86.9919],\n",
      "        [ 53.0353, -88.7563]]), tensor([[[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]],\n",
      "\n",
      "        [[ 1.5557, -0.2632],\n",
      "         [-0.2632,  0.4125]]]), (('value', bint(100)), ('state(time=1)', reals(2,)))), Tensor(tensor([-5.7941e-02, -6.5086e-01, -3.0121e+00, -7.0307e+00, -1.7322e+01,\n",
      "        -2.0985e+01, -4.4891e+01, -5.7472e+01, -5.9106e+01, -7.5486e+01,\n",
      "        -1.1463e+02, -1.1469e+02, -1.6306e+02, -1.6202e+02, -2.0521e+02,\n",
      "        -2.1650e+02, -2.7793e+02, -2.7444e+02, -3.1156e+02, -3.6858e+02,\n",
      "        -4.3107e+02, -4.4508e+02, -4.9012e+02, -5.5091e+02, -5.5113e+02,\n",
      "        -5.9742e+02, -7.0235e+02, -7.4223e+02, -7.9850e+02, -7.8182e+02,\n",
      "        -8.6493e+02, -8.9163e+02, -9.5537e+02, -1.0188e+03, -1.1223e+03,\n",
      "        -1.2201e+03, -1.2993e+03, -1.2798e+03, -1.3985e+03, -1.5117e+03,\n",
      "        -1.5154e+03, -1.6343e+03, -1.6754e+03, -1.8472e+03, -1.8400e+03,\n",
      "        -1.9274e+03, -2.0624e+03, -2.1917e+03, -2.1997e+03, -2.3336e+03,\n",
      "        -2.3647e+03, -2.4637e+03, -2.5608e+03, -2.7623e+03, -2.8887e+03,\n",
      "        -2.9431e+03, -3.0895e+03, -3.0864e+03, -3.3340e+03, -3.3795e+03,\n",
      "        -3.5296e+03, -3.5329e+03, -3.7125e+03, -3.7792e+03, -3.9830e+03,\n",
      "        -4.1023e+03, -4.2751e+03, -4.2816e+03, -4.5529e+03, -4.5347e+03,\n",
      "        -4.7850e+03, -4.9544e+03, -4.9910e+03, -5.0529e+03, -5.3604e+03,\n",
      "        -5.5148e+03, -5.5705e+03, -5.6314e+03, -5.7777e+03, -6.0109e+03,\n",
      "        -6.2400e+03, -6.3612e+03, -6.3772e+03, -6.5282e+03, -6.6876e+03,\n",
      "        -6.9325e+03, -7.1914e+03, -7.3499e+03, -7.5058e+03, -7.5249e+03,\n",
      "        -7.8821e+03, -8.0984e+03, -8.2492e+03, -8.2669e+03, -8.5495e+03,\n",
      "        -8.6250e+03, -8.9898e+03, -8.9974e+03, -9.1797e+03, -9.5538e+03]), OrderedDict([('value', bint(100))]))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) qiot\n",
      "*** NameError: name 'qiot' is not defined\n",
      "(Pdb) quit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5d80938ab146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0minterpretation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mreinterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-1e9bee2b04b4>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(track)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mbb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     result = sequential_sum_product(ops.logaddexp, ops.add,\n\u001b[0m\u001b[1;32m     48\u001b[0m                                     result, \"time\", {\"state\": \"state(time=1)\"})\n\u001b[1;32m     49\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-1e9bee2b04b4>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(track)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mbb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     result = sequential_sum_product(ops.logaddexp, ops.add,\n\u001b[0m\u001b[1;32m     48\u001b[0m                                     result, \"time\", {\"state\": \"state(time=1)\"})\n\u001b[1;32m     49\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pyro3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pyro3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/jpchen/anaconda/envs/pyro3/lib/python3.6/bdb.py\u001b[0m(70)\u001b[0;36mdispatch_line\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     68 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     69 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 70 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     72 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> quit\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "# params = [bias_cov, transition_matrix]\n",
    "params = covs\n",
    "optim = Adam(params, lr=1e-3)\n",
    "for i in range(num_epochs):\n",
    "    optim.zero_grad()\n",
    "    with interpretation(lazy):\n",
    "        log_prob = apply_optimizer(model(track))\n",
    "    loss = -reinterpret(log_prob).data\n",
    "    loss.backward()\n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "    optim.step()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the joint posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
