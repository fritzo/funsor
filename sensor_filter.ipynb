{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Sensor Bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import funsor\n",
    "import funsor.distributions as f_dist\n",
    "import funsor.ops as ops\n",
    "from funsor.interpreter import interpretation, reinterpret\n",
    "from funsor.optimizer import apply_optimizer\n",
    "from funsor.terms import lazy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate some synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sensors = 5\n",
    "num_steps = 100\n",
    "\n",
    "# simulate biased sensors\n",
    "sensors  = []\n",
    "for _ in range(num_sensors):\n",
    "    true_pos = 10 * torch.rand(2)  # in a box\n",
    "    biased_pos = true_pos + torch.randn(2)\n",
    "    sensors.append({\n",
    "        \"true_pos\": true_pos,\n",
    "        \"biased_pos\": biased_pos,\n",
    "    })\n",
    "\n",
    "# simulate a single track\n",
    "track = []\n",
    "z = 10 * torch.rand(2)  # initial state\n",
    "for t in range(num_steps):\n",
    "    # Advance latent state.\n",
    "    z += torch.randn(2)\n",
    "    z.clamp_(min=0, max=10)  # keep in the box\n",
    "    \n",
    "    # Observe via a random sensor.\n",
    "    sensor_id = pyro.sample('id', dist.Categorical(torch.ones(num_sensors)))\n",
    "    x = z - sensors[sensor_id][\"true_pos\"] + torch.randn(2)\n",
    "    track.append({\"sensor_id\": sensor_id, \"x\": x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up a tracking problem in Funsor. We start by modeling the biases of each sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME\n",
    "bias = funsor.pyro.mvn_to_funsor(\n",
    "    dist.MultivariateNormal(\n",
    "        torch.zeros(num_sensors, 2),\n",
    "        torch.eye(2, requires_grad=True)  # This can be learned\n",
    "    ),\n",
    "    (\"sensor_id\",),  # a batch dim\n",
    ")(value=\"bias\")\n",
    "# Instead create a giant joint Gaussian:\n",
    "bias = sum(\n",
    "    funsor.pyro.mvn_to_funsor(\n",
    "        dist.MultivariateNormal(\n",
    "            torch.zeros(2),\n",
    "            torch.eye(2, requires_grad=True)  # This can be learned\n",
    "        )\n",
    "    )(value=\"bias_{}\".format(i))\n",
    "    for i in range(num_sensors)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the filter in funsor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to funsor.pyro.hmm.GaussianHMM.__init__()\n",
    "init_dist = dist.MultivariateNormal(TODO)\n",
    "trans_matrix = TODO\n",
    "trans_dist = dist.MultivariateNormal(\n",
    "    torch.zeros(2),\n",
    "    torch.eye(2))\n",
    "obs_matrix = torch.eye(2)\n",
    "obs_dist = dist.MultivariateNormal(\n",
    "    torch.zeros(2),\n",
    "    torch.eye(2))\n",
    "\n",
    "init = dist_to_funsor(initial_dist)(value=\"state\")\n",
    "trans = matrix_and_mvn_to_funsor(transition_matrix, transition_dist,\n",
    "                                 (\"time\",), \"state\", \"state(time=1)\")\n",
    "obs = matrix_and_mvn_to_funsor(observation_matrix, observation_dist,\n",
    "                               (\"time\",), \"state(time=1)\", \"value\")\n",
    "# Now this is the crux, we add bias to the observation\n",
    "sensor_ids = funsor.torch.Tensor(\n",
    "    torch.tensor([frame[\"sensor_id\"] for frame in track]),\n",
    "    OrderedDict([(\"sensor_id\": bint(num_frames))]),\n",
    "    dtype=len(sensors)\n",
    ")\n",
    "biased_observations = funsor.torch.Tensor(\n",
    "    torch.tensor([frame[\"obs\"] for frame in track]),\n",
    "    OrderedDict([(\"sensor_id\": bint(num_frames))])\n",
    ")\n",
    "bias_over_time = bias(sensor_id=sensor_ids)\n",
    "obs = obs(value=TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to funsor.pyro.hmm.GaussianHMM.log_prob()\n",
    "ndims = max(len(self.batch_shape), value.dim() - self.event_dim)\n",
    "value = tensor_to_funsor(value, (\"time\",), event_output=self.event_dim - 1,\n",
    "                         dtype=self.dtype)\n",
    "\n",
    "obs = self._obs(value=value)\n",
    "result = self._trans + obs\n",
    "result = sequential_sum_product(ops.logaddexp, ops.add,\n",
    "                                result, \"time\", {\"state\": \"state(time=1)\"})\n",
    "result += self._init\n",
    "result = result.reduce(ops.logaddexp, frozenset([\"state\", \"state(time=1)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Finally we have a result that is a joint Gaussian over the biases.\n",
    "We can\n",
    "1. optimize all parameters to maximize `result.reduce(obs.logaddexp)`\n",
    "2. estimate the joint distribution over all bias parameters."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
