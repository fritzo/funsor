{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import functools\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import funsor\n",
    "from funsor.terms import Funsor, Variable, Number\n",
    "from funsor.tensor import Tensor\n",
    "from funsor.domains import Array, Bint, Real, Reals\n",
    "from funsor.factory import Bound, Fresh, Has, Value, make_funsor, to_funsor\n",
    "import funsor.ops as ops\n",
    "from funsor.cnf import Contraction\n",
    "from funsor.testing import random_tensor\n",
    "from funsor.interpretations import reflect\n",
    "\n",
    "funsor.set_backend(\"torch\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "%load_ext mypy_ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informal Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Tensor(\n",
    "    torch.tensor([[3., 1., 4.],\n",
    "                  [1., 5., 9.],\n",
    "                  [2., 6., 5.]]),\n",
    "    inputs=OrderedDict([(\"height\", Bint[3]), (\"width\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([3., 1., 4.]), OrderedDict([('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A(height=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([4., 9., 5.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A(width=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementwise operations and broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.9526, 0.7311, 0.9820],\n",
       "        [0.7311, 0.9933, 0.9999],\n",
       "        [0.8808, 0.9975, 0.9933]]), OrderedDict([('height', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sigmoid()  # 1 / (1 + (-A).exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor(\n",
    "    torch.tensor([2., 7., 1.]),\n",
    "    inputs=OrderedDict([(\"height\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")\n",
    "\n",
    "y = Tensor(\n",
    "    torch.tensor([1., 4., 1.]),\n",
    "    inputs=OrderedDict([(\"width\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 5.,  3.,  6.],\n",
       "        [ 8., 12., 16.],\n",
       "        [ 3.,  7.,  6.]]), OrderedDict([('height', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 4.,  5.,  5.],\n",
       "        [ 2.,  9., 10.],\n",
       "        [ 3., 10.,  6.]]), OrderedDict([('height', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([ 6., 12., 18.]), OrderedDict([('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(ops.add, reduced_vars=\"height\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([ 8., 15., 13.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(ops.add, reduced_vars=\"width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(36.0, OrderedDict(), 'real')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(ops.add, reduced_vars={\"height\", \"width\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([11., 30., 31.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A * y).reduce(ops.add, reduced_vars=\"width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([11., 30., 31.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Contraction(\n",
    "    red_op=ops.add,\n",
    "    bin_op=ops.mul,\n",
    "    reduced_vars=frozenset({Variable(\"width\", output=Bint[3])}),\n",
    "    terms=(A, y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([15., 43., 76.]), OrderedDict([('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x * x).reduce(ops.add, reduced_vars=\"height\")  # innder product\n",
    "x * y  # outer product\n",
    "(A * y).reduce(ops.add, reduced_vars=\"width\")  # matrix-vector product\n",
    "# vector-matrix product is the same as matrix-vector product\n",
    "(A * x).reduce(ops.add, reduced_vars=\"height\")  # vector-matrix product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = Tensor(\n",
    "    torch.tensor([[3, 2, 5], [5, 4, 0], [8, 3, 6]]),\n",
    "    inputs=OrderedDict([(\"width\", Bint[3]), (\"width'\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 46.,  22.,  39.],\n",
       "        [100.,  49.,  59.],\n",
       "        [ 76.,  43.,  40.]]), OrderedDict([('height', Bint[3, ]), (\"width'\", Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A * B).reduce(ops.add, reduced_vars=\"width\")  # matrix-matrix product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming and reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[3., 1., 4.],\n",
       "        [1., 5., 9.],\n",
       "        [2., 6., 5.]]), OrderedDict([(\"height'\", Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A(**{\"height\": \"height'\"})  # A(height=\"height'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "X0 = random_tensor(\n",
    "    OrderedDict([(\"input_layer\", Bint[input_dim])])\n",
    ")\n",
    "\n",
    "hidden_1_dim = 32\n",
    "W1 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"input_layer\", Bint[input_dim]),\n",
    "        (\"hidden_layer_1\", Bint[hidden_1_dim])\n",
    "    ])\n",
    ")\n",
    "b1 = random_tensor(\n",
    "    OrderedDict([(\"hidden_layer_1\", Bint[hidden_1_dim])])\n",
    ")\n",
    "X1 = ((W1 * X0).reduce(ops.add, \"input_layer\") + b1).sigmoid()\n",
    "\n",
    "hidden_2_dim = 16\n",
    "W2 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"hidden_layer_1\", Bint[hidden_1_dim]),\n",
    "        (\"hidden_layer_2\", Bint[hidden_2_dim])\n",
    "    ])\n",
    ")\n",
    "b2 = random_tensor(\n",
    "    OrderedDict([(\"hidden_layer_2\", Bint[hidden_2_dim])])\n",
    ")\n",
    "X2 = ((W2 * X1).reduce(ops.add, \"hidden_layer_1\") + b2).sigmoid()\n",
    "\n",
    "hidden_3_dim = 8\n",
    "W3 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"hidden_layer_2\", Bint[hidden_2_dim]),\n",
    "        (\"hidden_layer_3\", Bint[hidden_3_dim])\n",
    "    ])\n",
    ")\n",
    "b3 = random_tensor(\n",
    "    OrderedDict([(\"hidden_layer_3\", Bint[hidden_3_dim])])\n",
    ")\n",
    "X3 = ((W3 * X2).reduce(ops.add, \"hidden_layer_2\") + b3).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this correct?\n",
    "@make_funsor\n",
    "def FullConnLayer(\n",
    "    x: Has[{\"layer\"}],\n",
    "    W: Has[{\"layer\"}],\n",
    "    b: Funsor,\n",
    "    layer: Bound\n",
    ") -> Fresh[lambda x: x]:\n",
    "    result = ((W * x).reduce(ops.add, layer) + b).sigmoid()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([1.4654e-03, 4.1117e-01, 1.0000e+00, 1.0000e+00, 7.1454e-01, 1.0000e+00,\n",
       "        4.2027e-12, 4.1232e-06, 9.9991e-01, 1.9417e-04, 9.9754e-01, 6.8267e-12,\n",
       "        2.8535e-07, 9.8524e-01, 9.9350e-01, 9.9993e-01, 1.0000e+00, 9.9926e-01,\n",
       "        1.0000e+00, 9.5022e-02, 9.9571e-01, 3.1796e-02, 9.9969e-01, 4.1069e-04,\n",
       "        9.9307e-01, 8.3539e-01, 3.3728e-08, 7.8285e-01, 7.5796e-01, 1.5954e-02,\n",
       "        9.9961e-01, 9.9983e-01]), OrderedDict([('out_layer', Bint[32, ])]), 'real')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 100\n",
    "X0 = random_tensor(\n",
    "    OrderedDict([(\"layer\", Bint[input_dim])])\n",
    ")\n",
    "hidden_1_dim = 32\n",
    "W1 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"layer\", Bint[input_dim]),\n",
    "        (\"out_layer\", Bint[hidden_1_dim])\n",
    "    ])\n",
    ")\n",
    "b1 = random_tensor(\n",
    "    OrderedDict([(\"out_layer\", Bint[hidden_1_dim])])\n",
    ")\n",
    "\n",
    "with reflect:\n",
    "    FullConnLayer(X0, W1, b1, \"layer\")\n",
    "\n",
    "X1 = FullConnLayer(X0, W1, b1, \"layer\")\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def RecurrentLayer(\n",
    "    x: Funsor,\n",
    "    Wh: Funsor,\n",
    "    Wi: Funsor,\n",
    "    b: Funsor,\n",
    "    hidden: Bound,\n",
    "    input: Bound\n",
    ") -> Fresh[lambda x: x]:\n",
    "    output = ((Wh * h).reduce(ops.add, \"hidden\") + (Wi * x).reduce(ops.add, \"input\") + b).sigmoid()\n",
    "    return output(hidden=\"new_hidden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can Has be used here?\n",
    "@make_funsor\n",
    "def Softmax(\n",
    "    x: Funsor,\n",
    "    i: Funsor\n",
    ") -> Fresh[lambda x: x]:\n",
    "    return x.exp() / x.exp().reduce(ops.add, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Attention(\n",
    "    Q: Has[{\"key\"}],\n",
    "    K: Has[{\"key\", \"seq\"}],\n",
    "    V: Has[{\"seq\"}],\n",
    "    M: Has[{\"seq\"}], # does only one of Q, K, and M need to have \"seq\"?\n",
    "    key: Bound,\n",
    "    seq: Bound\n",
    ") -> Fresh[lambda Q: Q]:\n",
    "    x = (Q * K).reduce(ops.add, key) / math.sqrt(key.output.size) + M\n",
    "    return (Softmax(x, seq) * V).reduce(ops.add, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([-1.1402,  0.1616, -0.3963, -1.2688,  0.0687]), OrderedDict([('val', Bint[5, ])]), 'real')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = random_tensor(OrderedDict([(\"key\", Bint[10])]))\n",
    "k = random_tensor(OrderedDict([(\"key\", Bint[10]), (\"seq\", Bint[3])]))\n",
    "v = random_tensor(OrderedDict([(\"seq\", Bint[3]), (\"val\", Bint[5])]))\n",
    "m = random_tensor(OrderedDict([(\"seq\", Bint[3])]))\n",
    "Attention(q, k, v, m, \"key\", \"seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Unroll(\n",
    "    x: Funsor,\n",
    "    seq: Bound,\n",
    "    kernel: Funsor\n",
    ") -> Fresh[lambda x: x]:\n",
    "    temp_seq = Variable(\"temp_seq\", Bint[seq.output.size - kernel.output.size + 1])\n",
    "    return x(**{seq.name: temp_seq+kernel})(**{\"temp_seq\": seq.name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[[ 1.0071,  0.9979,  0.0461],\n",
       "         [ 0.9979,  0.0461, -1.5424],\n",
       "         [ 0.0461, -1.5424,  1.4369],\n",
       "         [-1.5424,  1.4369, -0.0624],\n",
       "         [ 1.4369, -0.0624,  0.6151],\n",
       "         [-0.0624,  0.6151,  0.0119],\n",
       "         [ 0.6151,  0.0119, -1.0266],\n",
       "         [ 0.0119, -1.0266, -1.0915]],\n",
       "\n",
       "        [[-0.4676, -1.5476,  0.0486],\n",
       "         [-1.5476,  0.0486,  0.4757],\n",
       "         [ 0.0486,  0.4757,  0.6420],\n",
       "         [ 0.4757,  0.6420, -0.0745],\n",
       "         [ 0.6420, -0.0745, -0.1132],\n",
       "         [-0.0745, -0.1132, -1.9013],\n",
       "         [-0.1132, -1.9013, -1.0457],\n",
       "         [-1.9013, -1.0457,  1.3052]],\n",
       "\n",
       "        [[-0.2131,  0.0280,  0.5392],\n",
       "         [ 0.0280,  0.5392,  1.0034],\n",
       "         [ 0.5392,  1.0034,  0.9759],\n",
       "         [ 1.0034,  0.9759,  1.4469],\n",
       "         [ 0.9759,  1.4469,  0.3573],\n",
       "         [ 1.4469,  0.3573, -0.9284],\n",
       "         [ 0.3573, -0.9284,  0.2496],\n",
       "         [-0.9284,  0.2496,  0.1293]]]), OrderedDict([('chans', Bint[3, ]), ('seq', Bint[8, ]), ('kernel', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"seq\", Bint[10])]))\n",
    "kernel = Variable(\"kernel\", Bint[3])\n",
    "Y = Unroll(X, \"seq\", kernel)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(tensor([ 0.6151, -0.1132,  0.3573]), OrderedDict([('chans', Bint[3, ])]), 'real'),\n",
       " Tensor(tensor([ 0.6151, -0.1132,  0.3573]), OrderedDict([('chans', Bint[3, ])]), 'real'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y(seq=4, kernel=2), X(seq=4+2) # i + j ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Conv1d(\n",
    "    X: Has[{\"chans\", \"seq\"}],\n",
    "    W: Has[{\"chans\", \"kernel\"}],\n",
    "    b: Funsor,\n",
    "    chans: Bound,\n",
    "    kernel: Bound,\n",
    "    seq: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return (W * Unroll(X, seq.name, kernel)).reduce(ops.add, frozenset({chans, kernel})) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"seq\", Bint[10])]))\n",
    "kernel = Variable(\"kernel\", Bint[3])\n",
    "w = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"kernel\", Bint[3])]))\n",
    "b = random_tensor(OrderedDict([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([-0.1743,  2.2894,  1.8864,  2.2908,  6.7270,  3.3832,  6.4320,  1.2325]), OrderedDict([('seq', Bint[8, ])]), 'real')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv1d(x, w, b, \"chans\", \"kernel\", \"seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Conv2d(\n",
    "    X: Has[{\"chans\", \"seq\"}],\n",
    "    W: Has[{\"chans\", \"kernel\"}],\n",
    "    b: Funsor,\n",
    "    chans: Bound,\n",
    "    kh: Bound,\n",
    "    height: Bound,\n",
    "    kw: Bound,\n",
    "    width: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return (W * Unroll(Unroll(X, width.name, kw), height.name, kh)).reduce(ops.add, frozenset({chans, kh, kw})) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ -5.9767, -14.7826,  -1.3400,  -6.0648,  -4.9239],\n",
       "        [ -6.6478,  -4.0896, -10.8918,   0.3870,   5.9537],\n",
       "        [  7.0979,  -8.1826,   3.0593,  -0.2431,  -4.0221],\n",
       "        [ -1.6603,  -2.7840,  -0.5078,  -3.2974,   4.2820],\n",
       "        [ -3.8931,  -5.6690,   1.3527,  -6.9459,  -4.1702],\n",
       "        [ -3.8460,  -9.1965,   2.9566,  -0.9288,  -0.2515],\n",
       "        [  0.2285,   4.0946, -16.1375,   1.8454, -14.1157],\n",
       "        [-13.8018,  -3.6187,   1.1990,  -7.7495,   8.8234]]), OrderedDict([('height', Bint[8, ]), ('width', Bint[5, ])]), 'real')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"height\", Bint[10]), (\"width\", Bint[8])]))\n",
    "kh = Variable(\"kh\", Bint[3])\n",
    "kw = Variable(\"kw\", Bint[4])\n",
    "w = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"kh\", Bint[3]), (\"kw\", Bint[4])]))\n",
    "b = random_tensor(OrderedDict([]))\n",
    "\n",
    "Conv2d(x, w, b, \"chans\", \"kh\", \"height\", \"kw\", \"width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Unflatten(\n",
    "    x: Funsor,\n",
    "    i: Bound,\n",
    "    i_over_2: Fresh[lambda i: Bint[i.size // 2]],\n",
    "    i_mod_2: Fresh[lambda: Bint[2]],\n",
    ") -> Fresh[lambda x: x]:\n",
    "    assert i.output.size % 2 == 0\n",
    "    return x(**{i.name: i_over_2 * Number(2, 3) + i_mod_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot infer domain of i=seq",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4fffcf008461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"seq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seq2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kernel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/funsor/funsor/factory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    193\u001b[0m                                 \u001b[0marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_funsor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot infer domain of {name}={arg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot infer domain of i=seq"
     ]
    }
   ],
   "source": [
    "# Partial evaluation\n",
    "X = random_tensor(OrderedDict([(\"seq\", Bint[10])]))\n",
    "X_var = Variable(\"x\", Bint[10])\n",
    "Y = Unflatten(X_var, \"seq\", \"seq2\", \"kernel\")\n",
    "Y(x=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Pool(\n",
    "    x: Funsor,\n",
    "    seq: Bound,\n",
    "    k: Value[int],\n",
    "    kernel: Fresh[lambda k: Bint[k]],\n",
    "    seq2: Fresh[lambda seq, k: Bint[seq.size // k]], # seq -> Bint[]\n",
    ") -> Fresh[lambda x: x]: # x -> x.output (Bint[] or Real)\n",
    "    seq2 = x.materialize(seq2)\n",
    "    kernel = x.materialize(kernel)\n",
    "    breakpoint()\n",
    "    return x(**{seq.name: seq2 * Number(k, k+1) + kernel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bint[7, ]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@make_funsor\n",
    "def Pool2(\n",
    "    x: Funsor,\n",
    "    seq: Bound,\n",
    "    kernel: Funsor,\n",
    "    seq2: Fresh[lambda seq, kernel: Bint[seq.size // kernel.output.size]], # seq -> Bint[]\n",
    ") -> Fresh[lambda x: x]: # x -> x.output (Bint[] or Real)\n",
    "    return x(**{seq.name: seq2 * Number(kernel.output.size, kernel.output.size+1) + kernel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pool(Tensor(tensor([-0.1375, -0.1264, -0.8750, -0.7947, -2.1557,  0.1106,  1.0998, -0.8064,\n",
       "         1.5379, -0.9541]), OrderedDict([('seq__BOUND_1', Bint[10, ])]), 'real'), Variable('seq__BOUND_1', Bint[10, ]), 2, Variable('kernel', Bint[2, ]), Variable('seq2', Bint[5, ]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = random_tensor(OrderedDict([(\"seq\", Bint[10])]))\n",
    "# kernel = Variable(\"kernel\", Bint[2])\n",
    "Y = Pool(X, \"seq\", 2, \"kernel\", \"seq2\")\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('kernel', Bint[2, ]), ('seq2', Bint[5, ])])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product[Bint[2, ], Bint[5, ]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funsor.terms.Tuple(kernel, temp_seq).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bint[5, ]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((temp_seq * Number(1, 3))).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bint[5, ]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(funkernel * temp_seq).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ca3e5da327e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_seq\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_seq' is not defined"
     ]
    }
   ],
   "source": [
    "X(seq=temp_seq+kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output mismatch: Bint[6, ] vs Bint[10, ]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-02567499a785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtemp_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"temp_seq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtemp_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/funsor/funsor/terms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0msubs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/funsor/funsor/terms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, arg, subs)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         subs = tuple(\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_funsor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         )\n",
      "\u001b[0;32m~/repos/funsor/funsor/terms.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         subs = tuple(\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_funsor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m         )\n\u001b[1;32m    830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/funsor/lib/python3.8/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    873\u001b[0m                             '1 positional argument')\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/funsor/funsor/terms.py\u001b[0m in \u001b[0;36mfunsor_to_funsor\u001b[0;34m(x, output, dim_to_name)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunsor_to_funsor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_to_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output mismatch: {} vs {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim_to_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         bint_names = {\n",
      "\u001b[0;31mValueError\u001b[0m: Output mismatch: Bint[6, ] vs Bint[10, ]"
     ]
    }
   ],
   "source": [
    "temp_seq = Variable(\"temp_seq\", Bint[5])\n",
    "X(seq=kernel+temp_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Mean(\n",
    "    X: Funsor,\n",
    "    ax: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return X.reduce(ops.add, ax) / ax.output.size\n",
    "\n",
    "@make_funsor\n",
    "def Variance(\n",
    "    X: Funsor,\n",
    "    ax: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return Mean((X - Mean(X, ax))**2, ax)\n",
    "\n",
    "@make_funsor\n",
    "def Standardize(\n",
    "    X: Funsor,\n",
    "    ax: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return (X - Mean(X, ax)) / (Variance(X, ax) + ops.finfo(X.data).eps)\n",
    "\n",
    "@make_funsor\n",
    "def BatchNorm(\n",
    "    X: Funsor,\n",
    "    gamma: Funsor,\n",
    "    beta: Funsor,\n",
    "    batch: Bound,\n",
    "    layer: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return Standardize(X, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([-2.0574, -0.4460,  1.0813,  0.4329,  0.9293, -0.0551,  0.2744, -0.5563,\n",
       "        -1.1598,  1.5569]), OrderedDict([('i', Bint[10, ])]), 'real')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random_tensor(OrderedDict([(\"i\", Bint[10])]))\n",
    "Standardize(x, \"i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_given_A = Tensor(\n",
    "    torch.tensor([[0.2, 0.3, 0.5],\n",
    "                  [0.8, 0.1, 0.1]]),\n",
    "    inputs=OrderedDict([(\"A\", Bint[2]), (\"B\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")\n",
    "\n",
    "A = Tensor(\n",
    "    torch.tensor([0.6, 0.4]),\n",
    "    inputs=OrderedDict([(\"A\", Bint[2])]),\n",
    "    dtype=\"real\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.1200, 0.1800, 0.3000],\n",
       "        [0.3200, 0.0400, 0.0400]]), OrderedDict([('A', Bint[2, ]), ('B', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_and_B = B_given_A * A\n",
    "A_and_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([0.4400, 0.2200, 0.3400]), OrderedDict([('B', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = A_and_B.reduce(ops.add, \"A\")\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.2727, 0.8182, 0.8824],\n",
       "        [0.7273, 0.1818, 0.1176]]), OrderedDict([('A', Bint[2, ]), ('B', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_given_B = A_and_B / B\n",
    "A_given_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sudoku ILP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random_tensor(OrderedDict([(\"batch\", Bint[10]), (\"d\", Bint[4])]))\n",
    "c = random_tensor(OrderedDict([(\"clusters\", Bint[3]), (\"d\", Bint[4])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTeX Macros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formal Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Records and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
