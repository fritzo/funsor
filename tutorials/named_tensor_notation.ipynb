{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import functools\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import funsor\n",
    "from funsor.terms import Funsor, Variable\n",
    "from funsor.tensor import Tensor\n",
    "from funsor.domains import Array, Bint, Real, Reals\n",
    "from funsor.factory import Bound, Fresh, Has, Value, make_funsor, to_funsor\n",
    "import funsor.ops as ops\n",
    "from funsor.cnf import Contraction\n",
    "from funsor.testing import random_tensor\n",
    "\n",
    "funsor.set_backend(\"torch\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "%load_ext mypy_ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informal Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Tensor(\n",
    "    torch.tensor([[3., 1., 4.],\n",
    "                  [1., 5., 9.],\n",
    "                  [2., 6., 5.]]),\n",
    "    inputs=OrderedDict([(\"height\", Bint[3]), (\"width\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([3., 1., 4.]), OrderedDict([('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A(height=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([4., 9., 5.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A(width=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementwise operations and broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.9526, 0.7311, 0.9820],\n",
       "        [0.7311, 0.9933, 0.9999],\n",
       "        [0.8808, 0.9975, 0.9933]]), OrderedDict([('height', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sigmoid()  # 1 / (1 + (-A).exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor(\n",
    "    torch.tensor([2., 7., 1.]),\n",
    "    inputs=OrderedDict([(\"height\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")\n",
    "\n",
    "y = Tensor(\n",
    "    torch.tensor([1., 4., 1.]),\n",
    "    inputs=OrderedDict([(\"width\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 5.,  3.,  6.],\n",
       "        [ 8., 12., 16.],\n",
       "        [ 3.,  7.,  6.]]), OrderedDict([('height', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 4.,  5.,  5.],\n",
       "        [ 2.,  9., 10.],\n",
       "        [ 3., 10.,  6.]]), OrderedDict([('height', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([ 6., 12., 18.]), OrderedDict([('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(ops.add, reduced_vars=\"height\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([ 8., 15., 13.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(ops.add, reduced_vars=\"width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(36.0, OrderedDict(), 'real')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(ops.add, reduced_vars={\"height\", \"width\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([11., 30., 31.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A * y).reduce(ops.add, reduced_vars=\"width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([11., 30., 31.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Contraction(\n",
    "    red_op=ops.add,\n",
    "    bin_op=ops.mul,\n",
    "    reduced_vars=frozenset({Variable(\"width\", output=Bint[3])}),\n",
    "    terms=(A, y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([15., 43., 76.]), OrderedDict([('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x * x).reduce(ops.add, reduced_vars=\"height\")  # innder product\n",
    "x * y  # outer product\n",
    "(A * y).reduce(ops.add, reduced_vars=\"width\")  # matrix-vector product\n",
    "# vector-matrix product is the same as matrix-vector product\n",
    "(A * x).reduce(ops.add, reduced_vars=\"height\")  # vector-matrix product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = Tensor(\n",
    "    torch.tensor([[3, 2, 5], [5, 4, 0], [8, 3, 6]]),\n",
    "    inputs=OrderedDict([(\"width\", Bint[3]), (\"width'\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 46.,  22.,  39.],\n",
       "        [100.,  49.,  59.],\n",
       "        [ 76.,  43.,  40.]]), OrderedDict([('height', Bint[3, ]), (\"width'\", Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A * B).reduce(ops.add, reduced_vars=\"width\")  # matrix-matrix product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming and reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[3., 1., 4.],\n",
       "        [1., 5., 9.],\n",
       "        [2., 6., 5.]]), OrderedDict([(\"height'\", Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A(**{\"height\": \"height'\"})  # A(height=\"height'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "X0 = random_tensor(\n",
    "    OrderedDict([(\"input_layer\", Bint[input_dim])])\n",
    ")\n",
    "\n",
    "hidden_1_dim = 32\n",
    "W1 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"input_layer\", Bint[input_dim]),\n",
    "        (\"hidden_layer_1\", Bint[hidden_1_dim])\n",
    "    ])\n",
    ")\n",
    "b1 = random_tensor(\n",
    "    OrderedDict([(\"hidden_layer_1\", Bint[hidden_1_dim])])\n",
    ")\n",
    "X1 = ((W1 * X0).reduce(ops.add, \"input_layer\") + b1).sigmoid()\n",
    "\n",
    "hidden_2_dim = 16\n",
    "W2 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"hidden_layer_1\", Bint[hidden_1_dim]),\n",
    "        (\"hidden_layer_2\", Bint[hidden_2_dim])\n",
    "    ])\n",
    ")\n",
    "b2 = random_tensor(\n",
    "    OrderedDict([(\"hidden_layer_2\", Bint[hidden_2_dim])])\n",
    ")\n",
    "X2 = ((W2 * X1).reduce(ops.add, \"hidden_layer_1\") + b2).sigmoid()\n",
    "\n",
    "hidden_3_dim = 8\n",
    "W3 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"hidden_layer_2\", Bint[hidden_2_dim]),\n",
    "        (\"hidden_layer_3\", Bint[hidden_3_dim])\n",
    "    ])\n",
    ")\n",
    "b3 = random_tensor(\n",
    "    OrderedDict([(\"hidden_layer_3\", Bint[hidden_3_dim])])\n",
    ")\n",
    "X3 = ((W3 * X2).reduce(ops.add, \"hidden_layer_2\") + b3).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: no issues found in 1 source file\n",
      "Type checking successful\n"
     ]
    }
   ],
   "source": [
    "%mypy\n",
    "\n",
    "# is this correct?\n",
    "@make_funsor\n",
    "def FullConnLayer(\n",
    "    x: Has[{\"layer\"}],\n",
    "    W: Has[{\"layer\", \"out_layer\"}],\n",
    "    b: Has[{\"out_layer\"}],\n",
    "    out_layer: Bound\n",
    ") -> Fresh[lambda x: x]:\n",
    "    result = ((W * x).reduce(ops.add, \"layer\") + b).sigmoid()\n",
    "    return result(out_layer=\"layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([5.1424e-05, 1.6135e-04, 6.2248e-01, 9.9984e-01, 9.9932e-01, 2.8701e-01,\n",
       "        1.0000e+00, 1.1595e-01, 1.0000e+00, 3.0341e-05, 1.2613e-07, 4.2051e-05,\n",
       "        1.1197e-06, 9.9520e-01, 9.9988e-01, 3.3333e-02, 2.7272e-01, 5.8579e-04,\n",
       "        7.3940e-04, 9.9880e-01, 4.9861e-01, 9.9999e-01, 9.8301e-01, 8.3890e-02,\n",
       "        2.2161e-04, 7.4274e-01, 1.0000e+00, 9.9943e-01, 8.3586e-01, 9.8640e-01,\n",
       "        1.0526e-12, 7.3241e-01]), OrderedDict([('layer', Bint[32, ])]), 'real')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 100\n",
    "X0 = random_tensor(\n",
    "    OrderedDict([(\"layer\", Bint[input_dim])])\n",
    ")\n",
    "hidden_1_dim = 32\n",
    "W1 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"layer\", Bint[input_dim]),\n",
    "        (\"out_layer\", Bint[hidden_1_dim])\n",
    "    ])\n",
    ")\n",
    "b1 = random_tensor(\n",
    "    OrderedDict([(\"out_layer\", Bint[hidden_1_dim])])\n",
    ")\n",
    "\n",
    "X1 = FullConnLayer(X0, W1, b1, \"out_layer\")\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def RecurrentLayer(\n",
    "    x: Funsor,\n",
    "    Wh: Funsor,\n",
    "    Wi: Funsor,\n",
    "    b: Funsor,\n",
    "    hidden: Bound,\n",
    "    input: Bound\n",
    ") -> Fresh[lambda x: x]:\n",
    "    output = ((Wh * h).reduce(ops.add, \"hidden\") + (Wi * x).reduce(ops.add, \"input\") + b).sigmoid()\n",
    "    return output(hidden=\"new_hidden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can Has be used here?\n",
    "@make_funsor\n",
    "def Softmax(\n",
    "    x: Funsor,\n",
    "    i: Funsor\n",
    ") -> Fresh[lambda x: x]:\n",
    "    return x.exp() / x.exp().reduce(ops.add, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Attention(\n",
    "    Q: Has[{\"key\"}],\n",
    "    K: Has[{\"key\"}],\n",
    "    V: Has[{\"seq\"}],\n",
    "    M: Has[{\"seq\"}], # does only one of Q, K, and M need to have \"seq\"?\n",
    "    key: Bound,\n",
    "    seq: Bound\n",
    ") -> Fresh[lambda Q: Q]:\n",
    "    x = (Q * K).reduce(ops.add, key) / math.sqrt(key.output.size) + M\n",
    "    return (Softmax(x, seq) * V).reduce(ops.add, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([-1.1402,  0.1616, -0.3963, -1.2688,  0.0687]), OrderedDict([('val', Bint[5, ])]), 'real')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = random_tensor(OrderedDict([(\"key\", Bint[10])]))\n",
    "k = random_tensor(OrderedDict([(\"key\", Bint[10]), (\"seq\", Bint[3])]))\n",
    "v = random_tensor(OrderedDict([(\"seq\", Bint[3]), (\"val\", Bint[5])]))\n",
    "m = random_tensor(OrderedDict([(\"seq\", Bint[3])]))\n",
    "Attention(q, k, v, m, \"key\", \"seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Unroll(\n",
    "    x: Funsor,\n",
    "    seq: Bound,\n",
    "    kernel: Funsor\n",
    ") -> Fresh[lambda x: x]:\n",
    "    temp_seq = Variable(\"temp_seq\", Bint[seq.output.size - kernel.output.size + 1])\n",
    "    return x(**{seq.name: temp_seq+kernel})(**{\"temp_seq\": seq.name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[[ 0.0196,  0.7319, -0.0750],\n",
       "         [ 0.7319, -0.0750, -0.0704],\n",
       "         [-0.0750, -0.0704, -1.5796],\n",
       "         [-0.0704, -1.5796, -1.2463],\n",
       "         [-1.5796, -1.2463,  1.5152],\n",
       "         [-1.2463,  1.5152, -0.9424],\n",
       "         [ 1.5152, -0.9424, -0.1457],\n",
       "         [-0.9424, -0.1457,  0.5838]],\n",
       "\n",
       "        [[ 0.3228, -0.6919,  1.5649],\n",
       "         [-0.6919,  1.5649, -0.2074],\n",
       "         [ 1.5649, -0.2074, -1.1792],\n",
       "         [-0.2074, -1.1792, -1.1265],\n",
       "         [-1.1792, -1.1265,  1.2414],\n",
       "         [-1.1265,  1.2414, -0.2144],\n",
       "         [ 1.2414, -0.2144,  0.3279],\n",
       "         [-0.2144,  0.3279,  1.8115]],\n",
       "\n",
       "        [[ 0.4639,  0.8814, -0.7432],\n",
       "         [ 0.8814, -0.7432, -0.4250],\n",
       "         [-0.7432, -0.4250, -0.9344],\n",
       "         [-0.4250, -0.9344, -0.6887],\n",
       "         [-0.9344, -0.6887,  1.0856],\n",
       "         [-0.6887,  1.0856, -0.0728],\n",
       "         [ 1.0856, -0.0728,  0.5321],\n",
       "         [-0.0728,  0.5321, -0.1135]]]), OrderedDict([('chans', Bint[3, ]), ('seq', Bint[8, ]), ('kernel', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"seq\", Bint[10])]))\n",
    "kernel = Variable(\"kernel\", Bint[3])\n",
    "Y = Unroll(X, \"seq\", kernel)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(tensor([1.5152, 1.2414, 1.0856]), OrderedDict([('chans', Bint[3, ])]), 'real'),\n",
       " Tensor(tensor([1.5152, 1.2414, 1.0856]), OrderedDict([('chans', Bint[3, ])]), 'real'))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y(seq=4, kernel=2), X(seq=4+2) # i + j ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Conv1d(\n",
    "    X: Has[{\"chans\", \"seq\"}],\n",
    "    W: Has[{\"chans\", \"kernel\"}],\n",
    "    b: Funsor,\n",
    "    chans: Bound,\n",
    "    kernel: Bound,\n",
    "    seq: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return (W * Unroll(X, seq.name, kernel)).reduce(ops.add, frozenset({chans, kernel})) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"seq\", Bint[10])]))\n",
    "kernel = Variable(\"kernel\", Bint[3])\n",
    "w = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"kernel\", Bint[3])]))\n",
    "b = random_tensor(OrderedDict([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([4.6129, 2.1073, 4.0671, 2.6048, 0.2089, 2.3785, 4.3914, 1.5787]), OrderedDict([('seq', Bint[8, ])]), 'real')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv1d(x, w, b, \"chans\", \"kernel\", \"seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Conv2d(\n",
    "    X: Has[{\"chans\", \"seq\"}],\n",
    "    W: Has[{\"chans\", \"kernel\"}],\n",
    "    b: Funsor,\n",
    "    chans: Bound,\n",
    "    kh: Bound,\n",
    "    height: Bound,\n",
    "    kw: Bound,\n",
    "    width: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return (W * Unroll(Unroll(X, width.name, kw), height.name, kh)).reduce(ops.add, frozenset({chans, kh, kw})) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[-6.1200e+00,  1.1318e+01,  5.0284e+00,  7.0467e+00,  4.2316e+00],\n",
       "        [-2.9635e+00, -2.3037e+00, -1.0457e+01,  2.2904e+00, -4.4439e-01],\n",
       "        [-8.4879e+00, -1.0425e+01,  5.7516e+00,  4.5685e-03,  1.1797e+01],\n",
       "        [ 6.4330e+00,  8.1517e+00,  1.0407e+01,  2.6766e+00, -1.3676e+00],\n",
       "        [-8.7566e-01, -4.7833e+00, -6.7619e+00,  7.9473e+00, -9.1501e+00],\n",
       "        [-4.6428e+00,  1.6236e+01,  1.5910e+00, -5.5439e+00,  5.9273e+00],\n",
       "        [ 1.2274e+01, -2.8410e+00,  8.8857e+00,  6.4797e+00,  2.3580e+00],\n",
       "        [-1.1778e+01,  1.2480e+01, -5.7598e+00,  4.2546e+00, -8.6591e-01]]), OrderedDict([('height', Bint[8, ]), ('width', Bint[5, ])]), 'real')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"height\", Bint[10]), (\"width\", Bint[8])]))\n",
    "kh = Variable(\"kh\", Bint[3])\n",
    "kw = Variable(\"kw\", Bint[4])\n",
    "w = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"kh\", Bint[3]), (\"kw\", Bint[4])]))\n",
    "b = random_tensor(OrderedDict([]))\n",
    "\n",
    "Conv2d(x, w, b, \"chans\", \"kh\", \"height\", \"kw\", \"width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Mean(\n",
    "    X: Funsor,\n",
    "    ax: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return X.reduce(ops.add, ax) / ax.output.size\n",
    "\n",
    "@make_funsor\n",
    "def Variance(\n",
    "    X: Funsor,\n",
    "    ax: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return Mean((X - Mean(X, ax))**2, ax)\n",
    "\n",
    "@make_funsor\n",
    "def Standardize(\n",
    "    X: Funsor,\n",
    "    ax: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return (X - Mean(X, ax)) / (Variance(X, ax) + ops.finfo(X.data).eps)\n",
    "\n",
    "@make_funsor\n",
    "def BatchNorm(\n",
    "    X: Funsor,\n",
    "    gamma: Funsor,\n",
    "    beta: Funsor,\n",
    "    batch: Bound,\n",
    "    layer: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return Standardize(X, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([-2.0574, -0.4460,  1.0813,  0.4329,  0.9293, -0.0551,  0.2744, -0.5563,\n",
       "        -1.1598,  1.5569]), OrderedDict([('i', Bint[10, ])]), 'real')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random_tensor(OrderedDict([(\"i\", Bint[10])]))\n",
    "Standardize(x, \"i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_given_A = Tensor(\n",
    "    torch.tensor([[0.2, 0.3, 0.5],\n",
    "                  [0.8, 0.1, 0.1]]),\n",
    "    inputs=OrderedDict([(\"A\", Bint[2]), (\"B\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")\n",
    "\n",
    "A = Tensor(\n",
    "    torch.tensor([0.6, 0.4]),\n",
    "    inputs=OrderedDict([(\"A\", Bint[2])]),\n",
    "    dtype=\"real\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.1200, 0.1800, 0.3000],\n",
       "        [0.3200, 0.0400, 0.0400]]), OrderedDict([('A', Bint[2, ]), ('B', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_and_B = B_given_A * A\n",
    "A_and_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([0.4400, 0.2200, 0.3400]), OrderedDict([('B', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = A_and_B.reduce(ops.add, \"A\")\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.2727, 0.8182, 0.8824],\n",
       "        [0.7273, 0.1818, 0.1176]]), OrderedDict([('A', Bint[2, ]), ('B', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_given_B = A_and_B / B\n",
    "A_given_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sudoku ILP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random_tensor(OrderedDict([(\"batch\", Bint[10]), (\"d\", Bint[4])]))\n",
    "c = random_tensor(OrderedDict([(\"clusters\", Bint[3]), (\"d\", Bint[4])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTeX Macros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formal Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Records and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
