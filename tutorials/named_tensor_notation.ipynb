{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FUNSOR_TYPECHECK=1\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import functools\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "\n",
    "%env FUNSOR_TYPECHECK=1\n",
    "import funsor\n",
    "from funsor.terms import Funsor, Variable, Number, Lambda, Slice\n",
    "from funsor.tensor import Tensor\n",
    "from funsor.domains import Array, Bint, Real, Reals\n",
    "from funsor.factory import Bound, Fresh, Has, Value, make_funsor, to_funsor\n",
    "import funsor.ops as ops\n",
    "from funsor.cnf import Contraction\n",
    "from funsor.testing import random_tensor\n",
    "from funsor.interpretations import reflect, memoize\n",
    "\n",
    "funsor.set_backend(\"torch\")\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informal Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Tensor(\n",
    "    torch.tensor([[3., 1., 4.],\n",
    "                  [1., 5., 9.],\n",
    "                  [2., 6., 5.]])\n",
    ")[\"height\", \"width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([3., 1., 4.]), OrderedDict([('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A(height=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([4., 9., 5.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A(width=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementwise operations and broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.9526, 0.7311, 0.9820],\n",
       "        [0.7311, 0.9933, 0.9999],\n",
       "        [0.8808, 0.9975, 0.9933]]), OrderedDict([('height', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sigmoid()  # 1 / (1 + (-A).exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor(torch.tensor([2., 7., 1.]))[\"height\"]\n",
    "\n",
    "y = Tensor(torch.tensor([1., 4., 1.]))[\"width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 5.,  3.,  6.],\n",
       "        [ 8., 12., 16.],\n",
       "        [ 3.,  7.,  6.]]), OrderedDict([('height', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 4.,  5.,  5.],\n",
       "        [ 2.,  9., 10.],\n",
       "        [ 3., 10.,  6.]]), OrderedDict([('height', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([ 6., 12., 18.]), OrderedDict([('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(ops.add, reduced_vars=\"height\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2.reduce(ops.add, \"hw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([ 8., 15., 13.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(ops.add, reduced_vars=\"width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(36.0, OrderedDict(), 'real')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(ops.add, reduced_vars={\"height\", \"width\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([11., 30., 31.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A * y).reduce(ops.add, reduced_vars=\"width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([15., 43., 76.]), OrderedDict([('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x * x).reduce(ops.add, reduced_vars=\"height\")  # innder product\n",
    "x * y  # outer product\n",
    "(A * y).reduce(ops.add, reduced_vars=\"width\")  # matrix-vector product\n",
    "# vector-matrix product is the same as matrix-vector product\n",
    "(A * x).reduce(ops.add, reduced_vars=\"height\")  # vector-matrix product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = Tensor(\n",
    "    torch.tensor([[3, 2, 5],\n",
    "                  [5, 4, 0],\n",
    "                  [8, 3, 6]]),\n",
    ")[\"width\", \"width2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 46.,  22.,  39.],\n",
       "        [100.,  49.,  59.],\n",
       "        [ 76.,  43.,  40.]]), OrderedDict([('height', Bint[3, ]), ('width2', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A * B).reduce(ops.add, reduced_vars=\"width\")  # matrix-matrix product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming and reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[3., 1., 4.],\n",
       "        [1., 5., 9.],\n",
       "        [2., 6., 5.]]), OrderedDict([('height2', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A(height=\"height2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[3., 1., 4.],\n",
       "        [1., 5., 9.],\n",
       "        [2., 6., 5.]]), OrderedDict([('height2', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str <-> Variable(str, ...) most of the time\n",
    "A(height=Variable(\"height2\", Bint[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "X0 = random_tensor(\n",
    "    OrderedDict([(\"input_layer\", Bint[input_dim])])\n",
    ")\n",
    "\n",
    "hidden_1_dim = 32\n",
    "W1 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"input_layer\", Bint[input_dim]),\n",
    "        (\"hidden_layer_1\", Bint[hidden_1_dim])\n",
    "    ])\n",
    ")\n",
    "b1 = random_tensor(\n",
    "    OrderedDict([(\"hidden_layer_1\", Bint[hidden_1_dim])])\n",
    ")\n",
    "X1 = ((W1 * X0).reduce(ops.add, \"input_layer\") + b1).sigmoid()\n",
    "\n",
    "hidden_2_dim = 16\n",
    "W2 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"hidden_layer_1\", Bint[hidden_1_dim]),\n",
    "        (\"hidden_layer_2\", Bint[hidden_2_dim])\n",
    "    ])\n",
    ")\n",
    "b2 = random_tensor(\n",
    "    OrderedDict([(\"hidden_layer_2\", Bint[hidden_2_dim])])\n",
    ")\n",
    "X2 = ((W2 * X1).reduce(ops.add, \"hidden_layer_1\") + b2).sigmoid()\n",
    "\n",
    "hidden_3_dim = 8\n",
    "W3 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"hidden_layer_2\", Bint[hidden_2_dim]),\n",
    "        (\"hidden_layer_3\", Bint[hidden_3_dim])\n",
    "    ])\n",
    ")\n",
    "b3 = random_tensor(\n",
    "    OrderedDict([(\"hidden_layer_3\", Bint[hidden_3_dim])])\n",
    ")\n",
    "X3 = ((W3 * X2).reduce(ops.add, \"hidden_layer_2\") + b3).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def FullConnLayer(\n",
    "    x: Has[{\"layer\"}],\n",
    "    W: Has[{\"layer\"}],\n",
    "    b: Funsor,\n",
    "    layer: Bound\n",
    ") -> Fresh[lambda x: x]:\n",
    "    result = ((W * x).reduce(ops.add, layer) + b).sigmoid()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([5.1250e-02, 3.9130e-01, 2.1275e-02, 9.1966e-07, 1.1757e-01, 9.2585e-09,\n",
       "        2.8901e-01, 2.3617e-02, 9.9739e-01, 9.9966e-01, 1.2796e-05, 7.0259e-01,\n",
       "        8.9353e-05, 1.0000e+00, 6.9404e-01, 7.0413e-05, 4.4894e-01, 1.4566e-02,\n",
       "        9.8803e-01, 9.7485e-01, 9.9999e-01, 9.8401e-01, 5.6814e-02, 9.9978e-01,\n",
       "        8.4199e-06, 7.8148e-01, 1.0000e+00, 9.5772e-01, 3.3361e-01, 4.8448e-05,\n",
       "        2.9235e-07, 6.8713e-02]), OrderedDict([('out_layer', Bint[32, ])]), 'real')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 100\n",
    "X0 = random_tensor(\n",
    "    OrderedDict([(\"layer\", Bint[input_dim])])\n",
    ")\n",
    "hidden_1_dim = 32\n",
    "W1 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"layer\", Bint[input_dim]),\n",
    "        (\"out_layer\", Bint[hidden_1_dim])\n",
    "    ])\n",
    ")\n",
    "b1 = random_tensor(\n",
    "    OrderedDict([(\"out_layer\", Bint[hidden_1_dim])])\n",
    ")\n",
    "\n",
    "X1 = FullConnLayer(X0, W1, b1, \"layer\")\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def RecurrentLayer(\n",
    "    x: Funsor,\n",
    "    Wh: Funsor,\n",
    "    Wi: Funsor,\n",
    "    b: Funsor,\n",
    "    hidden: Bound,\n",
    "    input: Bound\n",
    ") -> Fresh[lambda x: x]:\n",
    "    output = ((Wh * h).reduce(ops.add, \"hidden\") + (Wi * x).reduce(ops.add, \"input\") + b).sigmoid()\n",
    "    return output(hidden=\"new_hidden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Softmax(\n",
    "    x: Funsor,\n",
    "    ax: Bound,\n",
    "    ax2: Fresh[lambda ax: ax]\n",
    ") -> Fresh[lambda x: x]:\n",
    "    x = x(**{ax.name: ax2.name})\n",
    "    y = x - x.reduce(ops.logaddexp, ax2)\n",
    "    return y.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([0.0568, 0.1457, 0.0798, 0.0350, 0.0371, 0.2761, 0.2280, 0.0646, 0.0557,\n",
       "        0.0213]), OrderedDict([('key2', Bint[10, ])]), 'real')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = random_tensor(OrderedDict([(\"key\", Bint[10])]))\n",
    "Softmax(q, \"key\", \"key2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Attention(\n",
    "    Q: Has[{\"key\"}],\n",
    "    K: Has[{\"key\", \"seq\"}],\n",
    "    V: Has[{\"seq2\"}],\n",
    "    M: Has[{\"seq\"}],\n",
    "    key: Bound,\n",
    "    seq: Bound,\n",
    "    seq2: Bound\n",
    ") -> Fresh[lambda Q: Q]:\n",
    "    x = (Q * K).reduce(ops.add, key) / math.sqrt(key.output.size) + M\n",
    "    return (Softmax(x, seq, seq2) * V).reduce(ops.add, seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([ 0.2047, -0.2971, -0.8347, -0.6226, -0.0110]), OrderedDict([('val', Bint[5, ])]), 'real')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = random_tensor(OrderedDict([(\"key\", Bint[10])]))\n",
    "k = random_tensor(OrderedDict([(\"key\", Bint[10]), (\"seq\", Bint[3])]))\n",
    "v = random_tensor(OrderedDict([(\"seq2\", Bint[3]), (\"val\", Bint[5])]))\n",
    "m = random_tensor(OrderedDict([(\"seq\", Bint[3])]))\n",
    "Attention(q, k, v, m, \"key\", \"seq\", \"seq2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Unroll(\n",
    "    x: Has[{\"seq\"}],\n",
    "    seq: Bound,\n",
    "    k: Value[int],\n",
    "    kernel: Fresh[lambda k: Bint[k]],\n",
    "    seq2: Fresh[lambda seq, k: Bint[seq.size - k + 1]]\n",
    ") -> Fresh[lambda x: x]:\n",
    "    return x(**{seq.name: seq2 + kernel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Unroll2(\n",
    "    x: Funsor,\n",
    "    seq: Bound,\n",
    "    kernel: Funsor,\n",
    "    seq2: Fresh[lambda seq, kernel: Bint[seq.size - kernel.size + 1]]\n",
    ") -> Fresh[lambda x: x]:\n",
    "    return x(**{seq.name: seq2 + kernel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Conv1d(\n",
    "    X: Has[{\"chans\", \"seq\"}],\n",
    "    W: Has[{\"chans\", \"kernel\"}],\n",
    "    b: Funsor,\n",
    "    chans: Bound,\n",
    "    k: Value[int],\n",
    "    kernel: Bound,\n",
    "    seq: Bound,\n",
    "    seq2: Fresh[lambda seq, k: Bint[seq.size - k + 1]]\n",
    ") -> Fresh[lambda X: X]:\n",
    "    y = W * Unroll(X, seq, k, kernel, seq2)\n",
    "    return y.reduce(ops.add, frozenset({chans, kernel})) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"seq\", Bint[10])]))\n",
    "kernel = Variable(\"kernel\", Bint[3])\n",
    "w = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"kernel\", Bint[3])]))\n",
    "b = random_tensor(OrderedDict([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([1.1559, 2.6513, 1.8861, 1.7262, 2.6523, 3.2156, 6.6995, 0.6863]), OrderedDict([('seq2', Bint[8, ])]), 'real')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv1d(x, w, b, \"chans\", 3, \"kernel\", \"seq\", \"seq2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Conv2d(\n",
    "    X: Has[{\"chans\", \"height\", \"width\"}],\n",
    "    W: Has[{\"chans\", \"kh\", \"kw\"}],\n",
    "    b: Funsor,\n",
    "    chans: Bound,\n",
    "    kh_size: Value[int],\n",
    "    kh: Bound,\n",
    "    height: Bound,\n",
    "    height2: Fresh[lambda height, kh_size: Bint[height.size - kh_size + 1]],\n",
    "    kw_size: Value[int],\n",
    "    kw: Bound,\n",
    "    width: Bound,\n",
    "    width2: Fresh[lambda width, kw_size: Bint[width.size - kw_size + 1]]\n",
    ") -> Fresh[lambda X: X]:\n",
    "    y = W * Unroll(Unroll(X, width, kw_size, kw, width2), height, kh_size, kh, height2)\n",
    "    return y.reduce(ops.add, frozenset({chans, kh, kw})) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[  7.5981,   2.8738,  -4.6288,  -2.5880,   1.3028],\n",
       "        [-12.0374,   0.9402,   2.3095,   5.8484,   2.0857],\n",
       "        [ -4.9819,   4.1024,  -1.9617,  -6.0453,  -1.8697],\n",
       "        [ -6.6176,  -1.8181,   1.5590,   3.1369,  -4.0031],\n",
       "        [-11.5290,   2.9589,   6.5625,  -1.1461,  -4.2302],\n",
       "        [ -0.7835,   3.8283,  -6.6212,   2.4097,  11.8789],\n",
       "        [  4.7318,  -7.4386,  -0.3856,   2.9603,  15.1632],\n",
       "        [  2.6932,   2.0555,  10.2560, -12.5641, -13.1350]]), OrderedDict([('height2', Bint[8, ]), ('width2', Bint[5, ])]), 'real')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"height\", Bint[10]), (\"width\", Bint[8])]))\n",
    "w = random_tensor(OrderedDict([(\"chans\", Bint[3]), (\"kh\", Bint[3]), (\"kw\", Bint[4])]))\n",
    "b = random_tensor(OrderedDict([]))\n",
    "\n",
    "Conv2d(x, w, b, \"chans\", 3, \"kh\", \"height\", \"height2\", 4, \"kw\", \"width\", \"width2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Pool(\n",
    "    x: Has[{\"seq\"}],\n",
    "    seq: Bound,\n",
    "    k: Value[int],\n",
    "    kernel: Fresh[lambda k: Bint[k]],\n",
    "    seq2: Fresh[lambda seq, k: Bint[seq.size // k]], # seq -> Bint[]\n",
    ") -> Fresh[lambda x: x]: # x -> x.output (Bint[] or Real)\n",
    "    assert not seq.output.size % k\n",
    "    return x(**{seq.name: seq2 * Number(k, k+1) + kernel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[-1.8575,  1.0439],\n",
       "        [-0.1903,  0.5067],\n",
       "        [ 1.2351,  0.6842],\n",
       "        [-0.2534,  0.5630],\n",
       "        [-0.4049,  0.2481]]), OrderedDict([('seq2', Bint[5, ]), ('kernel', Bint[2, ])]), 'real')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = random_tensor(OrderedDict([(\"seq\", Bint[10])]))\n",
    "Y = Pool(X, \"seq\", 2, \"kernel\", \"seq2\")\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def MaxPool1d(\n",
    "    X: Has[{\"seq\"}],\n",
    "    seq: Bound,\n",
    "    k: Value[int],\n",
    "    kernel: Fresh[lambda k: Bint[k]],\n",
    "    seq2: Fresh[lambda seq, k: Bint[seq.size // k]]\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return Pool(X, seq, k, kernel, seq2).reduce(ops.max, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([ 0.9910,  0.4459,  0.9832,  0.4149, -0.0399]), OrderedDict([('seq2', Bint[5, ])]), 'real')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = random_tensor(OrderedDict([(\"seq\", Bint[10])]))\n",
    "Y = MaxPool1d(X, \"seq\", 2, \"kernel\", \"seq2\")\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def MaxPool2d(\n",
    "    X: Has[{\"height\", \"width\"}],\n",
    "    height: Bound,\n",
    "    kh_size: Value[int],\n",
    "    kh: Fresh[lambda kh_size: Bint[kh_size]],\n",
    "    height2: Fresh[lambda height, kh_size: Bint[height.size // kh_size]],\n",
    "    width: Bound,\n",
    "    kw_size: Value[int],\n",
    "    kw: Fresh[lambda kw_size: Bint[kw_size]],\n",
    "    width2: Fresh[lambda width, kw_size: Bint[width.size // kw_size]],\n",
    ") -> Fresh[lambda X: X]:\n",
    "    y = Pool(Pool(X, height, kh_size, kh, height2), width, kw_size, kw, width2)\n",
    "    return y.reduce(ops.max, frozenset({kh, kw}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[1.3635, 1.2425],\n",
       "        [1.7722, 1.2450],\n",
       "        [1.3647, 0.3712]]), OrderedDict([('width2', Bint[3, ]), ('height2', Bint[2, ])]), 'real')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = random_tensor(OrderedDict([(\"width\", Bint[9]), (\"height\", Bint[4])]))\n",
    "Y = MaxPool2d(X, \"height\", 2, \"kh\", \"height2\", \"width\", 3, \"kw\", \"width2\")\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Pool2(\n",
    "    x: Funsor,\n",
    "    seq: Bound,\n",
    "    kernel: Funsor,\n",
    "    seq2: Fresh[lambda seq, kernel: Bint[seq.size // kernel.size]], # seq -> Bint[]\n",
    ") -> Fresh[lambda x: x]: # x -> x.output (Bint[] or Real)\n",
    "    return x(**{seq.name: seq2 * Number(kernel.output.size, kernel.output.size+1) + kernel})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "x.sum(dim=0)\n",
    "x.mean(dim=0)\n",
    "\n",
    "# Funsor\n",
    "x.reduce(ops.add, \"i\")\n",
    "x.reduce(ops.mean, \"i\") # Wrong\n",
    "x.mean(\"i\")\n",
    "\n",
    "@make_funsor\n",
    "def Mean(\n",
    "    X: Funsor,\n",
    "    ax: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return ops.mean(funsor.terms.Lambda(X, ax), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Mean(\n",
    "    X: Has[{\"ax\"}],\n",
    "    ax: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return X.reduce(ops.add, ax) / ax.output.size\n",
    "\n",
    "@make_funsor\n",
    "def Mean2(\n",
    "    X: Has[{\"ax\", \"ax2\"}],\n",
    "    ax: Bound,\n",
    "    ax2: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return X.reduce(ops.add, frozenset({ax, ax2})) / (ax.output.size * ax2.output.size)\n",
    "\n",
    "@make_funsor\n",
    "def Variance(\n",
    "    X: Has[{\"ax\"}],\n",
    "    ax: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return Mean((X - Mean(X, ax))**2, ax)\n",
    "\n",
    "\n",
    "@make_funsor\n",
    "def Variance2(\n",
    "    X: Has[{\"ax\", \"ax2\"}],\n",
    "    ax: Bound,\n",
    "    ax2: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return Mean2((X - Mean2(X, ax, ax2))**2, ax, ax2)\n",
    "\n",
    "@make_funsor\n",
    "def Standardize(\n",
    "    X: Has[{\"ax\"}],\n",
    "    ax: Bound,\n",
    "    new_ax: Fresh[lambda ax: ax]\n",
    ") -> Fresh[lambda X: X]:\n",
    "    y = X(**{ax.name: new_ax})\n",
    "    return (y - Mean(X, ax)) / (Variance(X, ax) + ops.finfo(X.data).eps).sqrt()\n",
    "\n",
    "@make_funsor\n",
    "def Standardize2(\n",
    "    X: Has[{\"ax\", \"ax2\"}],\n",
    "    ax: Bound,\n",
    "    ax2: Bound,\n",
    "    new_ax: Fresh[lambda ax: ax],\n",
    "    new_ax2: Fresh[lambda ax2: ax2]\n",
    ") -> Fresh[lambda X: X]:\n",
    "    y = X(**{ax.name: new_ax, ax2.name: new_ax2})\n",
    "    return (y - Mean2(X, ax, ax2)) / (Variance2(X, ax, ax2) + ops.finfo(X.data).eps).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def BatchNorm(\n",
    "    X: Has[{\"batch\", \"layer\"}],\n",
    "    gamma: Funsor,\n",
    "    beta: Funsor,\n",
    "    batch: Bound,\n",
    "    layer: Bound,\n",
    "    batch2: Fresh[lambda batch: batch],\n",
    "    layer2: Fresh[lambda layer: layer]\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return Standardize2(X, batch, layer, batch2, layer2) * gamma + beta\n",
    "\n",
    "@make_funsor\n",
    "def InstanceNorm(\n",
    "    X: Has[{\"layer\"}],\n",
    "    gamma: Funsor,\n",
    "    beta: Funsor,\n",
    "    layer: Bound,\n",
    "    layer2: Fresh[lambda layer: layer]\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return Standardize(X, layer, layer2) * gamma + beta\n",
    "\n",
    "# same as BatchNorm\n",
    "@make_funsor\n",
    "def LayerNorm(\n",
    "    X: Has[{\"chans\", \"layer\"}],\n",
    "    gamma: Funsor,\n",
    "    beta: Funsor,\n",
    "    chans: Bound,\n",
    "    layer: Bound,\n",
    "    chans2: Fresh[lambda chans: chans],\n",
    "    layer2: Fresh[lambda layer: layer]\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return Standardize2(X, chans, layer, chans2, layer2) * gamma + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[[ 0.7576, -1.2169, -0.7666, -1.5257, -0.3424],\n",
       "         [ 0.9459,  1.8852,  2.5786,  0.3519,  0.5665],\n",
       "         [-0.4537, -0.0716,  0.8138,  0.2152,  0.7517]],\n",
       "\n",
       "        [[-0.4904,  1.3478, -1.4733, -0.1942, -0.4029],\n",
       "         [ 1.7668,  0.4327,  1.5611,  1.6400,  0.1874],\n",
       "         [ 0.1398, -0.2263,  1.2294, -0.0144,  0.0602]],\n",
       "\n",
       "        [[ 0.5309, -0.6889, -0.2520,  0.0214, -2.1402],\n",
       "         [ 1.0447, -1.0365,  1.2881,  1.8869, -0.1701],\n",
       "         [ 1.0926, -0.0163,  1.3467,  1.1819, -0.6966]],\n",
       "\n",
       "        [[-0.9197, -0.9453, -1.2733, -1.6563,  0.0826],\n",
       "         [ 0.4735, -0.4679, -1.1864, -1.6190,  1.5410],\n",
       "         [ 0.7206, -0.1800, -0.3657,  0.1576,  0.2392]]]), OrderedDict([('batch2', Bint[4, ]), ('chans', Bint[3, ]), ('layer2', Bint[5, ])]), 'real')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random_tensor(OrderedDict([(\"batch\", Bint[4]), (\"chans\", Bint[3]), (\"layer\", Bint[5])]))\n",
    "g = random_tensor(OrderedDict([(\"chans\", Bint[3])]))\n",
    "b = random_tensor(OrderedDict([(\"chans\", Bint[3])]))\n",
    "\n",
    "BatchNorm(x, g, b, \"batch\", \"layer\", \"batch2\", \"layer2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[[ 0.8866, -1.2136, -0.7346, -1.5421, -0.2834],\n",
       "         [ 0.2589,  1.5063,  2.4273, -0.5299, -0.2449],\n",
       "         [-0.5643, -0.0977,  0.9832,  0.2524,  0.9074]],\n",
       "\n",
       "        [[-0.8083,  0.9048, -1.7243, -0.5323, -0.7268],\n",
       "         [ 1.7700, -0.4627,  1.4257,  1.5577, -0.8731],\n",
       "         [ 0.1829, -0.2404,  1.4430,  0.0046,  0.0909]],\n",
       "\n",
       "        [[ 0.3900, -0.7483, -0.3406, -0.0854, -2.1027],\n",
       "         [ 1.1500, -1.0459,  1.4068,  2.0386, -0.1318],\n",
       "         [ 0.6735, -0.1453,  0.8610,  0.7394, -0.6475]],\n",
       "\n",
       "        [[-0.5441, -0.5816, -1.0625, -1.6239,  0.9253],\n",
       "         [ 1.3921,  0.4723, -0.2296, -0.6522,  2.4350],\n",
       "         [ 1.2515, -0.1676, -0.4602,  0.3643,  0.4930]]]), OrderedDict([('batch', Bint[4, ]), ('chans', Bint[3, ]), ('layer2', Bint[5, ])]), 'real')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InstanceNorm(x, g, b, \"layer\", \"layer2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Relu(\n",
    "    X: Funsor\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return ops.max(X, Number(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"chans\", Bint[3]),\n",
    "        (\"kh\", Bint[3]),\n",
    "        (\"kw\", Bint[4]),\n",
    "        (\"chans2\", Bint[3])\n",
    "    ]),\n",
    ")\n",
    "b1 = random_tensor(OrderedDict([(\"chans2\", Bint[3])]))\n",
    "W3 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"hidden\", Bint[3]),\n",
    "        (\"height3\", Bint[4]),\n",
    "        (\"width3\", Bint[4]),\n",
    "        (\"chans2\", Bint[3])\n",
    "    ]),\n",
    ")\n",
    "b3 = random_tensor(OrderedDict([(\"hidden\", Bint[3])]))\n",
    "W4 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"hidden\", Bint[3]),\n",
    "        (\"classes\", Bint[5]),\n",
    "    ]),\n",
    ")\n",
    "b4 = random_tensor(OrderedDict([(\"classes\", Bint[5])]))\n",
    "\n",
    "X0 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"batch\", Bint[4]),\n",
    "        (\"chans\", Bint[3]),\n",
    "        (\"height\", Bint[14]),\n",
    "        (\"width\", Bint[15])\n",
    "    ])\n",
    ")\n",
    "\n",
    "T1 = Relu(\n",
    "    Conv2d(X0, W1, b1, \"chans\", 3, \"kh\", \"height\", \"height2\", 4, \"kw\", \"width\", \"width2\")\n",
    ")\n",
    "X1 = MaxPool2d(T1, \"height2\", 3, \"kh\", \"height3\", \"width2\", 3, \"kw\", \"width3\")\n",
    "X3 = (W3 * X1).reduce(ops.add, frozenset({\"height3\", \"width3\", \"chans2\"})) + b3\n",
    "O = Softmax(((W4 * X3).reduce(ops.add, \"hidden\") + b4), \"classes\", \"classes2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 3.2374e-23, 2.6446e-35, 5.3192e-34],\n",
       "        [1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00]]), OrderedDict([('classes2', Bint[5, ]), ('batch', Bint[4, ])]), 'real')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_given_A = Tensor(\n",
    "    torch.tensor([[0.2, 0.3, 0.5],\n",
    "                  [0.8, 0.1, 0.1]]),\n",
    ")[\"A\", \"B\"]\n",
    "\n",
    "A = Tensor(\n",
    "    torch.tensor([0.6, 0.4]),\n",
    ")[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.1200, 0.1800, 0.3000],\n",
       "        [0.3200, 0.0400, 0.0400]]), OrderedDict([('A', Bint[2, ]), ('B', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain rule\n",
    "A_and_B = B_given_A * A\n",
    "A_and_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([0.4400, 0.2200, 0.3400]), OrderedDict([('B', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# marginalization\n",
    "B = A_and_B.reduce(ops.add, \"A\")\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.2727, 0.8182, 0.8824],\n",
       "        [0.7273, 0.1818, 0.1176]]), OrderedDict([('A', Bint[2, ]), ('B', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayes' rule\n",
    "A_given_B = A_and_B / B\n",
    "A_given_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 1.4886,  1.0406, -0.1764],\n",
       "        [-1.1459, -0.2191,  0.2646],\n",
       "        [-0.8871, -0.0130,  1.0426],\n",
       "        [ 0.3290,  0.2357, -0.4487],\n",
       "        [ 1.6252,  1.9409,  0.5970]]), OrderedDict([('vocab', Bint[5, ]), ('emb', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"vocab\", Bint[5]),\n",
    "        (\"emb\", Bint[3]),\n",
    "    ]),\n",
    ")\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([-0.8871, -0.0130,  1.0426]), OrderedDict([('emb', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# partial indexing\n",
    "E(vocab=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 0.3290,  0.2357, -0.4487],\n",
       "        [-0.8871, -0.0130,  1.0426],\n",
       "        [ 1.6252,  1.9409,  0.5970],\n",
       "        [ 1.4886,  1.0406, -0.1764]]), OrderedDict([('seq', Bint[4, ]), ('emb', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integer array indexing\n",
    "I = Tensor(torch.tensor([3, 2, 4, 0]), dtype=5)[\"seq\"]\n",
    "E(vocab=I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[-2.8599, -1.0175, -0.1075, -1.0871],\n",
       "        [-0.3646,  0.2439,  0.5320,  0.3238],\n",
       "        [-0.3164,  0.1753, -0.2921, -0.9764],\n",
       "        [ 2.2078,  0.2989, -0.2367, -0.8313],\n",
       "        [-2.0726,  0.1750,  2.4904,  0.2678]]), OrderedDict([('vocab', Bint[5, ]), ('seq', Bint[4, ])]), 'real')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather\n",
    "P = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"vocab\", Bint[5]),\n",
    "        (\"seq\", Bint[4]),\n",
    "    ]),\n",
    ")\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([ 2.2078,  0.1753,  2.4904, -1.0871]), OrderedDict([('seq', Bint[4, ])]), 'real')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P(vocab=I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([ 0.2989, -0.1075, -2.0726]), OrderedDict([('subseq', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I1 = Tensor(torch.tensor([1, 2, 0]), dtype=4)[\"subseq\"]\n",
    "I2 = Tensor(torch.tensor([3, 0, 4]), dtype=5)[\"subseq\"]\n",
    "P(seq=I1, vocab=I2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([1, 1, 1, 1]), OrderedDict([('seq', Bint[4, ])]), 1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Tensor(torch.tensor([[0, 1, 1, 0],\n",
    "                         [1, 0, 0, 0],\n",
    "                         [0, 0, 0, 1]]),\n",
    "           dtype=1)[\"vocab\", \"seq\"]\n",
    "X.reduce(ops.add, \"vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([7.2377e-01, 9.4771e-05, 2.4277e-01, 2.4577e-02, 8.7923e-03]), OrderedDict([('classes2', Bint[5, ])]), 'real')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"vocab\", Bint[3]),\n",
    "        (\"emb\", Bint[4]),\n",
    "    ]),\n",
    ")\n",
    "W = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"classes\", Bint[5]),\n",
    "        (\"emb\", Bint[4]),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "@make_funsor\n",
    "def CBOW(\n",
    "    X: Has[{\"vocab\", \"seq\"}],\n",
    "    E: Has[{\"emb\", \"vocab\"}],\n",
    "    W: Has[{\"emb\", \"classes\"}],\n",
    "    emb: Bound,\n",
    "    vocab: Bound,\n",
    "    seq: Bound,\n",
    "    classes: Bound,\n",
    "    classes2: Fresh[lambda classes: classes]\n",
    ") -> Fresh[lambda X: X]:\n",
    "    y = ((W * E).reduce(ops.add, emb) * X).reduce(ops.add, vocab).reduce(ops.add, seq)\n",
    "    return Softmax(y, classes, classes2)\n",
    "\n",
    "CBOW(X, E, W, \"emb\", \"vocab\", \"seq\", \"classes\", \"classes2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sudoku ILP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = random_tensor(OrderedDict([(\"batch\", Bint[10]), (\"d\", Bint[4])]))\n",
    "C = random_tensor(OrderedDict([(\"clusters\", Bint[3]), (\"d\", Bint[4])]))\n",
    "\n",
    "@make_funsor\n",
    "def Norm(\n",
    "    X: Has[{\"d\"}],\n",
    "    d: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return (X**2).reduce(ops.add, d).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implement reduce for ops.argmin and ops.argmax\n",
    "Q = Norm(C - X, \"d\").reduce(ops.argmin, \"clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Q * X / Q).reduce(ops.add, \"batch\") # ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Determinant(\n",
    "    F: Funsor,\n",
    "    ax1: Bound,\n",
    "    ax2: Bound\n",
    ") -> Fresh[lambda F: F]:\n",
    "    assert ax1.output.size == ax2.output.size\n",
    "    m = ax1.output.size\n",
    "    if m == 1:\n",
    "        return F(ax1=0, ax2=0)\n",
    "    else:\n",
    "        result = Number(0.0) # FIX ME\n",
    "        for i in range(m):\n",
    "            I1 = Tensor(torch.tensor([k for k in range(1, m)]), dtype=m)[ax1.name]\n",
    "            I2 = Tensor(torch.tensor([k for k in range(m) if k != i]), dtype=m)[ax2.name]\n",
    "            result += F(ax1=0, ax2=i) * Determinant(F(ax1=I1, ax2=I2))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Must provide exactly one type per subexpression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-82a077e3e8fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ax1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"ax2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDeterminant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ax1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ax2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/funsor/funsor/factory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdependent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_funsor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     @makefun.with_signature(\n",
      "\u001b[0;32m~/repos/funsor/funsor/terms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mlazy_property\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/funsor/funsor/interpreter.py\u001b[0m in \u001b[0;36minterpret\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minterpretation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreflect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mreflect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# for checking only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minterpretation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/funsor/funsor/interpretations.py\u001b[0m in \u001b[0;36minterpret\u001b[0;34m(self, cls, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subinterpretations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/funsor/funsor/interpretations.py\u001b[0m in \u001b[0;36minterpret\u001b[0;34m(self, cls, *args)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/funsor/funsor/factory.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_erase_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-24884005ee22>\u001b[0m in \u001b[0;36mDeterminant\u001b[0;34m(F, ax1, ax2)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mI1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mI2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mDeterminant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mI1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mI2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/funsor/funsor/factory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdependent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_funsor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     @makefun.with_signature(\n",
      "\u001b[0;32m~/repos/funsor/funsor/terms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mlazy_property\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/funsor/funsor/interpreter.py\u001b[0m in \u001b[0;36minterpret\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0minterpretation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_STACK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minterpretation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreflect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mreflect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# for checking only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minterpretation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/funsor/funsor/terms.py\u001b[0m in \u001b[0;36mreflect\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0marg_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mcls_specific\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_origin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg_types\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunsorMeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_specific\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ast_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/funsor/funsor/terms.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(cls, arg_types)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0marg_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marg_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         assert len(arg_types) == len(\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ast_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         ), \"Must provide exactly one type per subexpression\"\n",
      "\u001b[0;31mAssertionError\u001b[0m: Must provide exactly one type per subexpression"
     ]
    }
   ],
   "source": [
    "X = random_tensor(OrderedDict([(\"ax1\", Bint[2]), (\"ax2\", Bint[2])]))\n",
    "Determinant(X, \"ax1\", \"ax2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTeX Macros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formal Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Records and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number(6765.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dynamic programming\n",
    "@make_funsor\n",
    "def Fibbonaci(\n",
    "    k: Value[int]\n",
    ") -> Fresh[Real]:\n",
    "    if k == 0:\n",
    "        return Number(0.0)\n",
    "    if k == 1:\n",
    "        return Number(1.0)\n",
    "    return Fibbonaci(k - 1) + Fibbonaci(k - 2)\n",
    "\n",
    "with memoize():\n",
    "    y = Fibbonaci(20)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number(6765.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fibbonaci(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
