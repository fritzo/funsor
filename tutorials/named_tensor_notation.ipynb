{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mypy_ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext mypy_ipython\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import functools\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import funsor\n",
    "from funsor.terms import Funsor, Variable\n",
    "from funsor.tensor import Tensor\n",
    "from funsor.domains import Array, Bint, Real, Reals\n",
    "from funsor.factory import Bound, Fresh, Has, Value, make_funsor, to_funsor\n",
    "import funsor.ops as ops\n",
    "from funsor.cnf import Contraction\n",
    "from funsor.testing import random_tensor\n",
    "\n",
    "funsor.set_backend(\"torch\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "%load_ext mypy_ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informal Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Tensor(\n",
    "    torch.tensor([[3., 1., 4.],\n",
    "                  [1., 5., 9.],\n",
    "                  [2., 6., 5.]]),\n",
    "    inputs=OrderedDict([(\"height\", Bint[3]), (\"width\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([3., 1., 4.]), OrderedDict([('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A(height=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([4., 9., 5.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A(width=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementwise operations and broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.9526, 0.7311, 0.9820],\n",
       "        [0.7311, 0.9933, 0.9999],\n",
       "        [0.8808, 0.9975, 0.9933]]), OrderedDict([('height', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sigmoid()  # 1 / (1 + (-A).exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor(\n",
    "    torch.tensor([2., 7., 1.]),\n",
    "    inputs=OrderedDict([(\"height\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")\n",
    "\n",
    "y = Tensor(\n",
    "    torch.tensor([1., 4., 1.]),\n",
    "    inputs=OrderedDict([(\"width\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 5.,  3.,  6.],\n",
       "        [ 8., 12., 16.],\n",
       "        [ 3.,  7.,  6.]]), OrderedDict([('height', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 4.,  5.,  5.],\n",
       "        [ 2.,  9., 10.],\n",
       "        [ 3., 10.,  6.]]), OrderedDict([('height', Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([ 6., 12., 18.]), OrderedDict([('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(ops.add, reduced_vars=\"height\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([ 8., 15., 13.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(ops.add, reduced_vars=\"width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(36.0, OrderedDict(), 'real')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(ops.add, reduced_vars={\"height\", \"width\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([11., 30., 31.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A * y).reduce(ops.add, reduced_vars=\"width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([11., 30., 31.]), OrderedDict([('height', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Contraction(\n",
    "    red_op=ops.add,\n",
    "    bin_op=ops.mul,\n",
    "    reduced_vars=frozenset({Variable(\"width\", output=Bint[3])}),\n",
    "    terms=(A, y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([15., 43., 76.]), OrderedDict([('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x * x).reduce(ops.add, reduced_vars=\"height\")  # innder product\n",
    "x * y  # outer product\n",
    "(A * y).reduce(ops.add, reduced_vars=\"width\")  # matrix-vector product\n",
    "# vector-matrix product is the same as matrix-vector product\n",
    "(A * x).reduce(ops.add, reduced_vars=\"height\")  # vector-matrix product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = Tensor(\n",
    "    torch.tensor([[3, 2, 5], [5, 4, 0], [8, 3, 6]]),\n",
    "    inputs=OrderedDict([(\"width\", Bint[3]), (\"width'\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[ 46.,  22.,  39.],\n",
       "        [100.,  49.,  59.],\n",
       "        [ 76.,  43.,  40.]]), OrderedDict([('height', Bint[3, ]), (\"width'\", Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A * B).reduce(ops.add, reduced_vars=\"width\")  # matrix-matrix product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming and reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[3., 1., 4.],\n",
       "        [1., 5., 9.],\n",
       "        [2., 6., 5.]]), OrderedDict([(\"height'\", Bint[3, ]), ('width', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A(**{\"height\": \"height'\"})  # A(height=\"height'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "X0 = random_tensor(\n",
    "    OrderedDict([(\"input_layer\", Bint[input_dim])])\n",
    ")\n",
    "\n",
    "hidden_1_dim = 32\n",
    "W1 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"input_layer\", Bint[input_dim]),\n",
    "        (\"hidden_layer_1\", Bint[hidden_1_dim])\n",
    "    ])\n",
    ")\n",
    "b1 = random_tensor(\n",
    "    OrderedDict([(\"hidden_layer_1\", Bint[hidden_1_dim])])\n",
    ")\n",
    "X1 = ((W1 * X0).reduce(ops.add, \"input_layer\") + b1).sigmoid()\n",
    "\n",
    "hidden_2_dim = 16\n",
    "W2 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"hidden_layer_1\", Bint[hidden_1_dim]),\n",
    "        (\"hidden_layer_2\", Bint[hidden_2_dim])\n",
    "    ])\n",
    ")\n",
    "b2 = random_tensor(\n",
    "    OrderedDict([(\"hidden_layer_2\", Bint[hidden_2_dim])])\n",
    ")\n",
    "X2 = ((W2 * X1).reduce(ops.add, \"hidden_layer_1\") + b2).sigmoid()\n",
    "\n",
    "hidden_3_dim = 8\n",
    "W3 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"hidden_layer_2\", Bint[hidden_2_dim]),\n",
    "        (\"hidden_layer_3\", Bint[hidden_3_dim])\n",
    "    ])\n",
    ")\n",
    "b3 = random_tensor(\n",
    "    OrderedDict([(\"hidden_layer_3\", Bint[hidden_3_dim])])\n",
    ")\n",
    "X3 = ((W3 * X2).reduce(ops.add, \"hidden_layer_2\") + b3).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: no issues found in 1 source file\n",
      "Type checking successful\n"
     ]
    }
   ],
   "source": [
    "%mypy\n",
    "\n",
    "# is this correct?\n",
    "@make_funsor\n",
    "def FullConnLayer(\n",
    "    x: Has[{\"layer\"}],\n",
    "    W: Has[{\"layer\", \"out_layer\"}],\n",
    "    b: Has[{\"out_layer\"}],\n",
    "    out_layer: Bound\n",
    ") -> Fresh[lambda x: x]:\n",
    "    result = ((W * x).reduce(ops.add, \"layer\") + b).sigmoid()\n",
    "    return result(out_layer=\"layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([5.1424e-05, 1.6135e-04, 6.2248e-01, 9.9984e-01, 9.9932e-01, 2.8701e-01,\n",
       "        1.0000e+00, 1.1595e-01, 1.0000e+00, 3.0341e-05, 1.2613e-07, 4.2051e-05,\n",
       "        1.1197e-06, 9.9520e-01, 9.9988e-01, 3.3333e-02, 2.7272e-01, 5.8579e-04,\n",
       "        7.3940e-04, 9.9880e-01, 4.9861e-01, 9.9999e-01, 9.8301e-01, 8.3890e-02,\n",
       "        2.2161e-04, 7.4274e-01, 1.0000e+00, 9.9943e-01, 8.3586e-01, 9.8640e-01,\n",
       "        1.0526e-12, 7.3241e-01]), OrderedDict([('layer', Bint[32, ])]), 'real')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 100\n",
    "X0 = random_tensor(\n",
    "    OrderedDict([(\"layer\", Bint[input_dim])])\n",
    ")\n",
    "hidden_1_dim = 32\n",
    "W1 = random_tensor(\n",
    "    OrderedDict([\n",
    "        (\"layer\", Bint[input_dim]),\n",
    "        (\"out_layer\", Bint[hidden_1_dim])\n",
    "    ])\n",
    ")\n",
    "b1 = random_tensor(\n",
    "    OrderedDict([(\"out_layer\", Bint[hidden_1_dim])])\n",
    ")\n",
    "\n",
    "X1 = FullConnLayer(X0, W1, b1, \"out_layer\")\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def RecurrentLayer(\n",
    "    x: Funsor,\n",
    "    Wh: Funsor,\n",
    "    Wi: Funsor,\n",
    "    b: Funsor,\n",
    "    hidden: Bound,\n",
    "    input: Bound\n",
    ") -> Fresh[lambda x: x]:\n",
    "    output = ((Wh * h).reduce(ops.add, \"hidden\") + (Wi * x).reduce(ops.add, \"input\") + b).sigmoid()\n",
    "    return output(hidden=\"new_hidden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can Has be used here?\n",
    "@make_funsor\n",
    "def Softmax(\n",
    "    x: Funsor,\n",
    "    i: Funsor\n",
    ") -> Fresh[lambda x: x]:\n",
    "    return x.exp() / x.exp().reduce(ops.add, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Attention(\n",
    "    Q: Has[{\"key\"}],\n",
    "    K: Has[{\"key\"}],\n",
    "    V: Has[{\"seq\"}],\n",
    "    M: Has[{\"seq\"}], # does only one of Q, K, and M need to have \"seq\"?\n",
    "    key: Bound,\n",
    "    seq: Bound\n",
    ") -> Fresh[lambda Q: Q]:\n",
    "    x = (Q * K).reduce(ops.add, key) / math.sqrt(key.output.size) + M\n",
    "    return (Softmax(x, seq) * V).reduce(ops.add, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([-1.1402,  0.1616, -0.3963, -1.2688,  0.0687]), OrderedDict([('val', Bint[5, ])]), 'real')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = random_tensor(OrderedDict([(\"key\", Bint[10])]))\n",
    "k = random_tensor(OrderedDict([(\"key\", Bint[10]), (\"seq\", Bint[3])]))\n",
    "v = random_tensor(OrderedDict([(\"seq\", Bint[3]), (\"val\", Bint[5])]))\n",
    "m = random_tensor(OrderedDict([(\"seq\", Bint[3])]))\n",
    "Attention(q, k, v, m, \"key\", \"seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Unroll(\n",
    "    x: Funsor,\n",
    "    seq: Bound,\n",
    "    new_seq: Fresh[lambda seq: Bint[seq.size - 1]],\n",
    "    kernel: Fresh[lambda: Bint[2]],\n",
    ") -> Fresh[lambda x: x]:\n",
    "    return x(**{seq.name: new_seq+kernel-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[-2.4158, -0.3009],\n",
       "        [-0.3009, -0.0916],\n",
       "        [-0.0916,  0.3367],\n",
       "        [ 0.3367, -0.2952],\n",
       "        [-0.2952, -0.2060],\n",
       "        [-0.2060, -0.8539],\n",
       "        [-0.8539,  1.2039],\n",
       "        [ 1.2039, -1.1123],\n",
       "        [-1.1123, -1.9163]]), OrderedDict([('new_seq', Bint[9, ]), ('kernel', Bint[2, ])]), 'real')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = random_tensor(OrderedDict([(\"seq\", Bint[10])]))\n",
    "# Unroll(q, \"seq\", \"new_seq\", \"kernel\")\n",
    "new_seq = Variable(\"new_seq\", Bint[9])\n",
    "kernel = Variable(\"kernel\", Bint[2])\n",
    "q(seq=new_seq+kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable('new_seq', Bint[9, ]) + Variable('kernel', Bint[2, ]).reduce(nullop, set())"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_seq + kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v(seq=2, kernel=1) == q(seq=2+1-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_funsor\n",
    "def Mean(\n",
    "    X: Funsor,\n",
    "    ax: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return X.reduce(ops.add, ax) / ax.output.size\n",
    "\n",
    "@make_funsor\n",
    "def Variance(\n",
    "    X: Funsor,\n",
    "    ax: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return Mean((X - Mean(X, ax))**2, ax)\n",
    "\n",
    "@make_funsor\n",
    "def Standardize(\n",
    "    X: Funsor,\n",
    "    ax: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return (X - Mean(X, ax)) / (Variance(X, ax) + ops.finfo(X.data).eps)\n",
    "\n",
    "@make_funsor\n",
    "def BatchNorm(\n",
    "    X: Funsor,\n",
    "    gamma: Funsor,\n",
    "    beta: Funsor,\n",
    "    batch: Bound,\n",
    "    layer: Bound\n",
    ") -> Fresh[lambda X: X]:\n",
    "    return Standardize(X, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([-2.0574, -0.4460,  1.0813,  0.4329,  0.9293, -0.0551,  0.2744, -0.5563,\n",
       "        -1.1598,  1.5569]), OrderedDict([('i', Bint[10, ])]), 'real')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random_tensor(OrderedDict([(\"i\", Bint[10])]))\n",
    "Standardize(x, \"i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_given_A = Tensor(\n",
    "    torch.tensor([[0.2, 0.3, 0.5],\n",
    "                  [0.8, 0.1, 0.1]]),\n",
    "    inputs=OrderedDict([(\"A\", Bint[2]), (\"B\", Bint[3])]),\n",
    "    dtype=\"real\"\n",
    ")\n",
    "\n",
    "A = Tensor(\n",
    "    torch.tensor([0.6, 0.4]),\n",
    "    inputs=OrderedDict([(\"A\", Bint[2])]),\n",
    "    dtype=\"real\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.1200, 0.1800, 0.3000],\n",
       "        [0.3200, 0.0400, 0.0400]]), OrderedDict([('A', Bint[2, ]), ('B', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_and_B = B_given_A * A\n",
    "A_and_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([0.4400, 0.2200, 0.3400]), OrderedDict([('B', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = A_and_B.reduce(ops.add, \"A\")\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(tensor([[0.2727, 0.8182, 0.8824],\n",
       "        [0.7273, 0.1818, 0.1176]]), OrderedDict([('A', Bint[2, ]), ('B', Bint[3, ])]), 'real')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_given_B = A_and_B / B\n",
    "A_given_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sudoku ILP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random_tensor(OrderedDict([(\"batch\", Bint[10]), (\"d\", Bint[4])]))\n",
    "c = random_tensor(OrderedDict([(\"clusters\", Bint[3]), (\"d\", Bint[4])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTeX Macros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formal Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Records and shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
